{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaGomez/F5-MOEA-Variations/blob/main/examples/MOEA_Brachistochrone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Brachistochrone Problem\n",
        "\n",
        "\n",
        "The Brachistochone is the famous problem to find the shape of the curve down wich a bead sliding from rest and accelerated by gravity will slip (**without friction**) from one point to another in the least time. \n",
        "\n",
        "\"The shortest path and the shortest time\""
      ],
      "metadata": {
        "id": "V5OgCX-uSKiC"
      },
      "id": "V5OgCX-uSKiC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive"
      ],
      "metadata": {
        "id": "bSarzpyxomuq"
      },
      "id": "bSarzpyxomuq"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8kqoZE5OZqw",
        "outputId": "cda42df1-32c9-4eec-eee0-073476be400d"
      },
      "id": "I8kqoZE5OZqw",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Necessary libraries "
      ],
      "metadata": {
        "id": "jKXvtPViof0u"
      },
      "id": "jKXvtPViof0u"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvlOFpaZOdCg",
        "outputId": "31a2ca46-86a2-4d9d-ab0c-ef4d9b6b6e6d"
      },
      "id": "BvlOFpaZOdCg",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 784 kB in 1s (660 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 63.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.11.0+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
            "Collecting ale-py~=0.7.4\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3[extra]) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (5.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.46.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
            "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616823 sha256=a041f52c399d5f98e59dbe533384758b680c7a36a64e475f1a86b21f17a9581b\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=e3f429101c62e41901e2fedcaa8298777b7b3e45ad0005d2ad6e9bc852166dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built gym AutoROM.accept-rom-license\n",
            "Installing collected packages: gym, AutoROM.accept-rom-license, autorom, stable-baselines3, ale-py\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2 gym-0.21.0 stable-baselines3-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Imports "
      ],
      "metadata": {
        "id": "bdOQei6WopoR"
      },
      "id": "bdOQei6WopoR"
    },
    {
      "cell_type": "code",
      "source": [
        "## RL Libraries\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import numpy as np \n",
        "import gym\n",
        "import random\n",
        "\n",
        "## GA Libraries\n",
        "import subprocess\n",
        "import glob\n",
        "import json\n",
        "import base64\n",
        "import csv\n",
        "\n",
        "from gym import spaces\n",
        "from datetime import datetime, date\n",
        "\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "from stable_baselines3.ddpg.policies import MlpPolicy\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from scipy.optimize import newton, fsolve\n",
        "from scipy.integrate import quad\n",
        "from math import sqrt,sin,cos\n",
        "from random import shuffle, randint\n",
        "from copy import deepcopy\n",
        "\n",
        "#for render function\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython import display\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Jzy_CXU7Ofay"
      },
      "id": "Jzy_CXU7Ofay",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Reinforcement Learning Process (RL)"
      ],
      "metadata": {
        "id": "kMImDe5lo4Xd"
      },
      "id": "kMImDe5lo4Xd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "0G4UbtpuoqjO"
      },
      "id": "0G4UbtpuoqjO"
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/gdrive/My Drive/Brachistochrone/RL\"\n",
        "models_path = os.path.join(base_path, \"saved_models/\")\n",
        "logs_path = os.path.join(base_path, \"logs/\")\n",
        "tensorboard_path = os.path.join(base_path, \"barchistostrone_ddpg_tensorboard\")\n",
        "\n",
        "selected_path = \"\"\n",
        "best_model_path = \"\"\n",
        "log_path = \"\"\n",
        "tensorboard_log = \"\"\n",
        "normalization_path = \"\"\n",
        "stats_path = \"\"\n",
        "hypdict_path = \"\"\n",
        "SELECTED_MODEL = \"generalized_final_1\"\n",
        "\n",
        "\"\"\"SET GOAL and MODEL\"\"\"\n",
        "goal = (8.0, -6.0)\n",
        "#SELECTED_MODEL = 'generalized_final_'+str(Brachistochrone_Env.active_friction)+'_'+str(Brachistochrone_Env.dt)+'_'+str(Brachistochrone_Env.init_angle)+'_'+str(Brachistochrone_Env.sol_space_padding)"
      ],
      "metadata": {
        "id": "O4gVMoC3Ok-r"
      },
      "id": "O4gVMoC3Ok-r",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "Aei7xpA8qUuz"
      },
      "id": "Aei7xpA8qUuz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Functions"
      ],
      "metadata": {
        "id": "gCZShbmgowkN"
      },
      "id": "gCZShbmgowkN"
    },
    {
      "cell_type": "code",
      "source": [
        "def change_selected_model():\n",
        "  global selected_path, best_model_path, log_path, tensorboard_log, normalization_path, stats_path, hypdict_path\n",
        "  selected_path = os.path.join(models_path, SELECTED_MODEL)\n",
        "  best_model_path = os.path.join(models_path, SELECTED_MODEL, \"best_model\")\n",
        "  log_path = os.path.join(logs_path, SELECTED_MODEL, \"logs\")\n",
        "  tensorboard_log = os.path.join(tensorboard_path, SELECTED_MODEL)\n",
        "  normalization_path = os.path.join(models_path, SELECTED_MODEL, \"normalizer_stat\")\n",
        "  stats_path = os.path.join(normalization_path, \"vecnormalize.pkl\")\n",
        "  hypdict_path = os.path.join(models_path, SELECTED_MODEL, \"HypDict.txt\")\n",
        "\n",
        "  # Check folders exist on Drive\n",
        "  os.makedirs(selected_path, exist_ok=True)\n",
        "  os.makedirs(best_model_path, exist_ok=True)\n",
        "  os.makedirs(log_path, exist_ok=True)\n",
        "  os.makedirs(tensorboard_log, exist_ok=True)\n",
        "  os.makedirs(normalization_path, exist_ok=True)\n",
        "\n",
        "change_selected_model()\n",
        "\n",
        "\n",
        "def cycloid(P1,P2,N):\n",
        "  \"\"\"Return the path of Brachistochrone curve from (0,0) to (x2, y2).\n",
        "  The Brachistochrone curve is the path down which a bead will fall without\n",
        "  friction between two points in the least time (an arc of a cycloid).\n",
        "  It is returned as an array of N values of (x,y) between (0,0) and (x2,y2).\n",
        "  \"\"\"\n",
        "\n",
        "  # First find theta2 from (x2, y2) numerically (by Newton-Rapheson).\n",
        "  f = lambda theta: -P2[1]/P2[0] - (1-np.cos(theta))/(theta-np.sin(theta))\n",
        "  theta2 = newton(f, np.pi/2)\n",
        "\n",
        "  # The radius of the circle generating the cycloid.\n",
        "  R = -P2[1] / (1 - np.cos(theta2))\n",
        "\n",
        "  theta = np.linspace(0, theta2, N)\n",
        "  x = R * (theta - np.sin(theta))\n",
        "  y = R * (1 - np.cos(theta))\n",
        "\n",
        "  # The time of travel\n",
        "  T = theta2 * np.sqrt(R / Brachistochrone_Env.g)\n",
        "  return x, y, T\n",
        "\n",
        "\n",
        "def rect(P1,P2,N):\n",
        "  \"\"\"Return the rectilinear straight path from (0,0) to (x2, y2).\"\"\"\n",
        "  x_interval = np.linspace(P1[0],P2[0],N)\n",
        "  m = float(P2[1] - P1[1])/(P2[0]-P1[0])\n",
        "  q = P1[1] - (m*P1[0])\n",
        "  f_y = lambda x: m*x+q\n",
        "  y = [f_y(x) for x in x_interval]\n",
        "  T_rett = sqrt(2*(P2[0]**2+P2[1]**2)/(-Brachistochrone_Env.g*P2[1]))\n",
        "  \n",
        "  return x_interval,y,T_rett\n",
        "\n",
        "\n",
        "def plot_solution(x,y,goal,title= None,savef=False):\n",
        "  if (len(x)!=0):\n",
        "    #plot results\n",
        "    cycloid_x, cycloid_y, cycloid_T = cycloid((0,0), goal, len(x))\n",
        "    rect_x, rect_y, rect_T = rect((0,0), goal, len(x))\n",
        "    print('Time taken by cycloid = ', cycloid_T)\n",
        "    print('Time taken by linear solution = ', rect_T)\n",
        "                \n",
        "    time_taken = len(x)/(1/Brachistochrone_Env.dt)\n",
        "    plt.plot(x,y , label = 'Path by RL agent, time taken =  %fs' %time_taken)\n",
        "    plt.plot(cycloid_x, -cycloid_y, label='Brachistochrone, time taken =  %fs' %cycloid_T)\n",
        "    plt.plot(rect_x, rect_y, label='Linear, time taken =  %fs' %rect_T)\n",
        "    plt.scatter(x[-1], y[-1], color = 'green', s = 100.0)\n",
        "    plt.scatter(x[0], y[0], color = 'red', s = 100.0)\n",
        "    plt.scatter(goal[0], goal[1], color = 'blue', s=100.0)\n",
        "    plt.annotate('Start', (x[0], y[0]))\n",
        "    plt.annotate('End', (x[-1], y[-1]))\n",
        "    plt.annotate('Goal', goal)\n",
        "    plt.legend()\n",
        "    plt.xlabel('X-COORDINATE(m)')\n",
        "    plt.ylabel('Y-COORDINATE(m)')\n",
        "    if (title is None):\n",
        "      plt.title('TRAJECTORY')\n",
        "    else:\n",
        "      plt.title(title)\n",
        "    if (savef):\n",
        "      plot_path = os.path.join(models_path, \"%s/%s.png\"%(title,title))\n",
        "      plt.savefig(plot_path, bbox_inches='tight')\n",
        "    plt.show()\n",
        "  else:\n",
        "      print(\"error: no x,y pairs provided\")"
      ],
      "metadata": {
        "id": "S4kTABdLRpbk"
      },
      "id": "S4kTABdLRpbk",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Clases"
      ],
      "metadata": {
        "id": "iEsMoXo7GnJS"
      },
      "id": "iEsMoXo7GnJS"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "11bb4aa5-300c-4406-a0cc-9a9c4feebc13",
      "metadata": {
        "tags": [],
        "id": "11bb4aa5-300c-4406-a0cc-9a9c4feebc13"
      },
      "outputs": [],
      "source": [
        "class Schedule(object):\n",
        "  def value(self, step):\n",
        "    \"\"\"\n",
        "    Value of the schedule for a given timestep\n",
        "\n",
        "    :param step: (int) the timestep\n",
        "    :return: (float) the output value for the given timestep\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "class LinearSchedule(Schedule):\n",
        "  \"\"\"\n",
        "  Linear interpolation between initial_p and final_p over\n",
        "  schedule_timesteps. After this many timesteps pass final_p is\n",
        "  returned.\n",
        "\n",
        "  :param schedule_timesteps: (int) Number of timesteps for which to linearly anneal initial_p to final_p\n",
        "  :param initial_p: (float) initial output value\n",
        "  :param final_p: (float) final output value\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
        "    self.schedule_timesteps = schedule_timesteps\n",
        "    self.final_p = final_p\n",
        "    self.initial_p = initial_p\n",
        "\n",
        "\n",
        "  def value(self, step):\n",
        "    fraction = min(float(step) / self.schedule_timesteps, 1.0)\n",
        "    return self.initial_p + fraction * (self.final_p - self.initial_p)\n",
        "\n",
        "\n",
        "class SaveVecNormalizeCallback(BaseCallback):\n",
        "  \"\"\"\n",
        "  Callback for saving a VecNormalize wrapper every ``save_freq`` steps\n",
        "  :param save_freq: (int)\n",
        "  :param save_path: (str) Path to the folder where ``VecNormalize`` will be saved, as ``vecnormalize.pkl``\n",
        "  :param name_prefix: (str) Common prefix to the saved ``VecNormalize``, if None (default)\n",
        "      only one file will be kept.\n",
        "  \"\"\"\n",
        "  def __init__(self, save_freq: int, save_path: str, name_prefix:str = None, verbose: int = 0):\n",
        "    super().__init__(verbose)\n",
        "    self.save_freq = save_freq\n",
        "    self.save_path = save_path\n",
        "    self.name_prefix = name_prefix\n",
        "\n",
        "\n",
        "  def _init_callback(self) -> None:\n",
        "    # Create folder if needed\n",
        "    if self.save_path is not None:\n",
        "      try:\n",
        "        os.makedirs(self.save_path, exist_ok=True)\n",
        "      except:\n",
        "        pass #folder already exist\n",
        "\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.n_calls % self.save_freq == 0:\n",
        "      if self.name_prefix is not None:\n",
        "        path = os.path.join(self.save_path, f\"{self.name_prefix}_{self.num_timesteps}_steps.pkl\")\n",
        "      else:\n",
        "        path = os.path.join(self.save_path, \"vecnormalize.pkl\")\n",
        "      if self.model.get_vec_normalize_env() is not None:\n",
        "        self.model.get_vec_normalize_env().save(path)\n",
        "        if self.verbose > 1:\n",
        "          print(f\"Saving VecNormalize to {path}\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brachistochrone Environment"
      ],
      "metadata": {
        "id": "21mOjvTjpBfF"
      },
      "id": "21mOjvTjpBfF"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8b742c9e-9d25-4def-b86c-79c37a8274e1",
      "metadata": {
        "id": "8b742c9e-9d25-4def-b86c-79c37a8274e1"
      },
      "outputs": [],
      "source": [
        "#discrete action space generating theta variation in [-k;k] interval with step: 0.5\n",
        "class Brachistochrone_Env(gym.Env):\n",
        "    \n",
        "    dt = 0.2 #HYP\n",
        "    init_angle = -90.0 #define the initial value for angle of fall\n",
        "    renderOnReset = False #set to false to speed up training\n",
        "    active_friction = True #switch friction ON/OFF\n",
        "    dynamic_friction_coeff = 0.05 #dynamic friction coefficient for friction estimation\n",
        "    granularity = 0.5 #distance between subsequent angle-variation values from action space\n",
        "    ylbMagnitude = 1.3 #factor to give extra-dimension along y-dim and relax feasible region\n",
        "    action_space_padding = 2.5 #>1.3 factor to give more exploration capability to the agent: could be useful in constrained/alternative problems formulation\n",
        "    g=10 #gravity constant\n",
        "    #more params..\n",
        "    \n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        super(Brachistochrone_Env, self).__init__()\n",
        "        self.states = np.array([0.0, 0.0, 0.0 ,Brachistochrone_Env.init_angle]) #pos_x, pos_y, vel, #theta from +ve x axis\n",
        "        self.target_pos = np.array([+8.0, -6.0])\n",
        "        self.g = -Brachistochrone_Env.g\n",
        "        self.dt = Brachistochrone_Env.dt\n",
        "        self.reward = 0.0\n",
        "        self.tot_reward = 0.0\n",
        "        self.init_err_position = sqrt((self.target_pos[0])**2 + (self.target_pos[1])**2)\n",
        "        self.time_steps = 0\n",
        "        self.renderOnReset = Brachistochrone_Env.renderOnReset\n",
        "        self.action_space_padding_factor = Brachistochrone_Env.action_space_padding\n",
        "        self.ylbMagnitude = Brachistochrone_Env.ylbMagnitude\n",
        "        self.target_steps = self.target_steps_bounder(self.target_pos)\n",
        "        self.refinementf = False\n",
        "        \n",
        "        \n",
        "        \"\"\"counter for render activity during training\"\"\"\n",
        "        self.counter_rend = 200 #RENDER PROGRAMMED SWITCH-OFF\n",
        "        \n",
        "        self.action_seq = []\n",
        "        \n",
        "        #defining a feasible reward threshold according to specified dt\n",
        "        self.reward_threshold = sqrt(0.5*Brachistochrone_Env.g*self.init_err_position)*Brachistochrone_Env.dt\n",
        "        #for rendering purpose\n",
        "        self.x_ep = [0]\n",
        "        self.y_ep = [0]\n",
        "        self.video = [(0,0)]\n",
        "        \n",
        "        \"\"\"feasible region boundary\"\"\"\n",
        "        self.x_right_boundary = self.target_pos[0]+self.reward_threshold\n",
        "        self.y_lower_boundary = (Brachistochrone_Env.ylbMagnitude)*self.target_pos[1]-self.reward_threshold\n",
        "\n",
        "        \"\"\"\n",
        "        act_val_high = np.array([90.0])\n",
        "        act_val_low = np.array([-90.0])\n",
        "        self.action_space = spaces.Box(low = act_val_low, high = act_val_high, shape = (1,), dtype=np.float32)\n",
        "        \"\"\"\n",
        "        self.action_set, self.theta_bound = self.action_space_init(self.target_pos)\n",
        "        self.action_space = spaces.Discrete(self.action_set)#discrete action space\n",
        "        \n",
        "        obs_val_high = np.array([100.0, 100.0, 1000.0, 0.0])\n",
        "        obs_val_low = np.array([-100.0, -100.0, -1000.0,-90.0])\n",
        "        self.observation_space = spaces.Box(low= obs_val_low, high = obs_val_high, shape=(4,), dtype=np.float32)\n",
        "        #print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+str(self.action_space_padding_factor))\n",
        "\n",
        "    def action_space_init(self,target_p):\n",
        "        \"\"\"compute k' as boundary for action space, k'> k, where k is the theoretical derivative of theta angle in optimal cycloid solution\"\"\"\n",
        "        # action_set cardinality is given as a function of granularity\n",
        "        \n",
        "        #lower bound time to fall between starting point and goal position \n",
        "        goal_distance = self.init_err_position\n",
        "        t_lb = sqrt(2*goal_distance / Brachistochrone_Env.g)\n",
        "        #upper bound to angle variation in the path (based on theta variation)\n",
        "        tot_delta_angle_ub = 180 #°\n",
        "        \n",
        "        angle_variation_ub = math.ceil(tot_delta_angle_ub / t_lb / (1/self.dt))\n",
        "        \n",
        "        granularity = Brachistochrone_Env.granularity #delta between two consecutive angles\n",
        "        #action_set_cardinality = math.ceil(2* angle_variation_ub / Brachistochrone_Env.granularity) #variation\n",
        "        action_set_cardinality = math.ceil(angle_variation_ub / Brachistochrone_Env.granularity)\n",
        "        return action_set_cardinality, angle_variation_ub\n",
        "        \n",
        "    def action_discretizer(self,action_value):\n",
        "        #discretization is used to vary final found solution, and is made on non-normalized action space\n",
        "        disp =self.theta_bound/self.action_set\n",
        "        domain = [x for x in np.arange(0,self.action_set+disp,disp)]\n",
        "        action = min(domain, key=lambda x:abs(x-action_value))\n",
        "        \n",
        "        return action\n",
        "    \n",
        "    def action_space_norm(self,action):\n",
        "        granularity = Brachistochrone_Env.granularity\n",
        "        #action = - self.theta_bound + (action*granularity) #variation\n",
        "        action = (action*granularity)\n",
        "        return action\n",
        "    \n",
        "    def step(self, action):\n",
        "        dt = self.dt\n",
        "        # action corresponds to theta\n",
        "        angle_variation = self.action_space_norm(action)\n",
        "        original_theta = self.states[3]\n",
        "        final_theta = original_theta + angle_variation\n",
        "\n",
        "        original_vel = self.states[2]\n",
        "        initial_vel_x = original_vel*cos(math.radians(original_theta))\n",
        "        initial_vel_y = original_vel*sin(math.radians(original_theta))\n",
        "        \n",
        "        acceleration = self.g*sin(math.radians(final_theta)) #can be positive or negative\n",
        "        \n",
        "        #apply friction if needed\n",
        "        if (Brachistochrone_Env.active_friction):\n",
        "            #computing friction actiong along the plane\n",
        "            ortogonal_acceleration = self.g*cos(math.radians(final_theta))\n",
        "            friction_deceleration = abs(Brachistochrone_Env.dynamic_friction_coeff* ortogonal_acceleration) # always positive \n",
        "            if (acceleration>=0):\n",
        "                acceleration = acceleration - friction_deceleration\n",
        "            if (acceleration<0):\n",
        "                acceleration = acceleration + friction_deceleration\n",
        "            \n",
        "        #compute x,y components of acceleration\n",
        "        acceleration_x = acceleration*cos(math.radians(final_theta)) #\n",
        "        acceleration_y = acceleration*sin(math.radians(final_theta)) #\n",
        "        \n",
        "\n",
        "        displacement_x = (initial_vel_x*dt) + (0.5*acceleration_x*(dt**2))\n",
        "        displacement_y = (initial_vel_y*dt) + (0.5*acceleration_y*(dt**2))\n",
        "        displacement = sqrt(displacement_x**2 + displacement_y**2)\n",
        "\n",
        "        final_vel_x = initial_vel_x + acceleration_x*dt\n",
        "        final_vel_y = initial_vel_y + acceleration_y*dt\n",
        "\n",
        "        final_x = self.states[0] + displacement_x\n",
        "        final_y = self.states[1] + displacement_y\n",
        "        final_vel = sqrt(final_vel_x**2 + final_vel_y**2)\n",
        "\n",
        "        self.states[0] = final_x\n",
        "        self.states[1] = final_y\n",
        "        self.states[2] = final_vel\n",
        "        self.states[3] = final_theta\n",
        "\n",
        "        #updating path\n",
        "        self.x_ep.append(final_x)\n",
        "        self.y_ep.append(final_y)\n",
        "        self.video.append((final_x,final_y))\n",
        "\n",
        "        \"\"\"APPLY POLICY\"\"\"\n",
        "        err_position = sqrt((self.states[0] - self.target_pos[0])**2 + (self.states[1] - self.target_pos[1])**2)\n",
        "\n",
        "        #r1 define the reward for getting closer to the target \n",
        "        r1 = 1 - (err_position/self.init_err_position)\n",
        "        #r2 define the reward for being fast to get the goal\n",
        "        r2 = 1 - (self.time_steps/self.target_steps)\n",
        "        \n",
        "        \"\"\"f reward weights\"\"\"\n",
        "        w1= 2 #first try was 1\n",
        "        w2= 1\n",
        "        self.reward = w1*r1+w2*r2 # you can think to 1s as weights for scalarization method\n",
        "        done=False\t\n",
        "        self.time_steps+=1\n",
        "        if self.time_steps >= self.target_steps:\n",
        "            print(\"fine steps\")\n",
        "            #if steps are over and target not reached we give a negative reward equal to negative max step reward\n",
        "            self.reward = -(w1+w2) \n",
        "            #print(\"goodexit\"+str((self.time_steps >= self.target_steps,err_position <= self.reward_threshold)))\n",
        "            done = True\n",
        "            \n",
        "        #verificare se devo fare il replacement di last step con il passo extra\n",
        "        if self.refinementf:\n",
        "            #print(\"refinement in corso\")\n",
        "            #we replace last_pos with optimal inter-position\n",
        "            last_pos = self.final_step_refinement()\n",
        "            final_x, self.x_ep[-1], self.states[0] = last_pos[0], last_pos[0], last_pos[0]\n",
        "            final_y, self.y_ep[-1], self.states[1] = last_pos[1], last_pos[1], last_pos[1]\n",
        "            self.reward = (w1+w2)*(self.target_steps - self.time_steps)\n",
        "            done = True\n",
        "            \n",
        "            \n",
        "        if err_position <= self.reward_threshold and not self.refinementf:#se siamo nel cerchio target\n",
        "            #print(\"colpito target area\")\n",
        "            self.refinementf = self.check_step_refinement()\n",
        "            if not self.refinementf:\n",
        "                done = True\n",
        "            self.reward = (w1+w2)*(self.target_steps - self.time_steps)\n",
        "            \n",
        "        if final_x > (self.x_right_boundary) or final_x < -1.0 or final_y > 0.0 or final_y < (self.y_lower_boundary) or displacement_x<0:\n",
        "            #print(\"bad exit\")\n",
        "            self.reward = -1*(w1+w2)*(self.target_steps - self.time_steps)\n",
        "            #print(\"badexit\"+str((final_x > (self.x_right_boundary),displacement_x<0)))\n",
        "            done = True\n",
        "        #new termination condition\n",
        "        if (self.renderOnReset and self.counter_rend>0):\n",
        "            print(\"-------|\"+str(final_theta)+\";\"+str(self.reward)+\"|--------------\")\n",
        "\n",
        "        info = {'g_component':acceleration}\n",
        "        self.tot_reward +=self.reward\n",
        "        #if (done==True):\n",
        "            #print(\"<<<< n_step:%d, last_x_displacement:%f, final_x:%f >>>>>\"%(self.time_steps,self.target_steps,displacement_x))\n",
        "        return self.states, self.reward, done, info\n",
        "\n",
        "    def final_step_refinement(self):\n",
        "        last_pos = np.array([self.x_ep[-1],self.y_ep[-1]])#end of line\n",
        "        prec_pos = np.array([self.x_ep[-2],self.y_ep[-2]])# start of line\n",
        "        p_opt = [self.target_pos[0], self.target_pos[1]] #point to project\n",
        "        \n",
        "        l2 = np.sum((prec_pos-last_pos)**2)\n",
        "        #The line extending the segment is parameterized as prec_pos + t (last_pos - prec_pos).\n",
        "        #The projection falls where t = [(p_opt-prec_pos) . (last_pos-prec_pos)] / |last_pos-prec_pos|^2\n",
        "\n",
        "        #if you need the point to project on line extention connecting prec_pos and last_pos\n",
        "        t = np.sum((p_opt - prec_pos) * (last_pos - prec_pos)) / l2\n",
        "\n",
        "        #if you need to ignore if p_opt does not project onto line segment\n",
        "        if t > 1 or t < 0:\n",
        "            return(last_pos[0],last_pos[1])\n",
        "\n",
        "        #if you need the point to project on line segment between prec_pos and last_pos or closest point of the line segment\n",
        "        t = max(0, min(1, np.sum((p_opt - prec_pos) * (last_pos - prec_pos)) / l2))\n",
        "\n",
        "        projection = prec_pos + t * (last_pos - prec_pos)\n",
        "        return(round(projection[0],3),round(projection[1],3))\n",
        "\n",
        "\n",
        "    def check_step_refinement(self):\n",
        "        \n",
        "        if (self.states[0]>self.target_pos[0]-self.reward_threshold and self.states[0]<self.target_pos[0] and self.states[1]<self.target_pos[1]+self.reward_threshold and self.states[1]>self.target_pos[1] -self.reward_threshold):\n",
        "            return True\n",
        "        else:\n",
        "            #print(\"final_x > target_x - r:%r, final_y:%r, final_x < target_x:%r, target_x:{}, target_y:{}\"%(self.states[0],self.states[1], self.target_pos[0], self.target_pos[1]))\n",
        "            return False\n",
        "        \n",
        "        \n",
        "    def reset(self):\n",
        "                #render and reset trace\n",
        "        self.counter_rend =self.counter_rend - 1\n",
        "        if (self.renderOnReset== True and self.counter_rend>0):\n",
        "            self.render(mode=\"auto\")\n",
        "            print(\"<<<TOT. EP. REWARD: %f>>>\"%(self.tot_reward))\n",
        "        self.x_ep.clear()\n",
        "        self.y_ep.clear()\n",
        "        self.time_steps = 0\n",
        "        self.reward = 0.0\n",
        "        self.tot_reward = 0.0\n",
        "        self.refinementf = False\n",
        "        self.states = np.array([0.0, 0.0, 0.0 ,Brachistochrone_Env.init_angle])\n",
        "\n",
        "        return self.states\n",
        "    \n",
        "    def animate(self,frame_num):\n",
        "        x = (x[0] for x in self.video[0])\n",
        "        y = (x[1] for x in self.video[0])\n",
        "        line.set_data((x, y))\n",
        "        return line\n",
        "    \n",
        "    def target_steps_bounder(self,target_pos: tuple):\n",
        "        \"\"\"trying to cut all sub-optimal solutions dinamically selecting max. steps per episode from trivial linear solution\"\"\"\n",
        "        if (target_pos[1]>=0):\n",
        "            raise Exception(\"error: unfeasible path given\")\n",
        "        L = target_pos[0] #we suppose paths are built between (0,0) and (x_t,y_t) for normalization reasons\n",
        "        H = target_pos[1]\n",
        "        T_rett = sqrt(2*(L**2+H**2)/(-Brachistochrone_Env.g*H))\n",
        "        #this method must return number of maximum steps\n",
        "        N_target_steps = T_rett/self.dt*(self.action_space_padding_factor)\n",
        "        return int(math.ceil(N_target_steps))\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_steps_bounder(target_pos: tuple):\n",
        "        if (target_pos[1]>=0):\n",
        "            raise Exception(\"error: unfeasible path given\")\n",
        "        L = target_pos[0] #we suppose paths are built between (0,0) and (x_t,y_t) for normalization reasons\n",
        "        H = target_pos[1]\n",
        "        T_rett = sqrt(2*(L**2+H**2)/(-Brachistochrone_Env.g*H))\n",
        "        #this method must return number of maximum steps\n",
        "        N_target_steps = T_rett/self.dt*(Brachistochrone_Env.action_space_padding)\n",
        "        return int(math.ceil(N_target_steps))\n",
        "        \n",
        "    def render(self,mode='human'):\n",
        "        if (len(self.x_ep)!=0):\n",
        "            goal = self.target_pos\n",
        "            time_taken = self.time_steps*(self.dt)\n",
        "            x = np.array(self.x_ep)\n",
        "            y = np.array(self.y_ep)\n",
        "            circle1 = plt.Circle(goal, self.reward_threshold, color='r', fill=False)\n",
        "            fig, ax = plt.subplots()\n",
        "            plt.plot(x,y , label = 'Path by RL agent, time taken =  %fs' %time_taken)\n",
        "            plt.scatter(x[-1], y[-1], color = 'green', s = 100.0)\n",
        "            plt.scatter(x[0], y[0], color = 'red', s = 100.0)\n",
        "            plt.scatter(goal[0], goal[1], color = 'blue', s=100.0)\n",
        "            ax.add_patch(circle1)\n",
        "            plt.annotate('Start', (x[0], y[0]))\n",
        "            plt.annotate('End', (x[-1], y[-1]))\n",
        "            plt.annotate('Goal', goal)\n",
        "            plt.legend()\n",
        "            \"\"\"draw boundary of feasible region\"\"\"\n",
        "            plt.axhline(y=self.y_lower_boundary, color='r', linestyle='-')\n",
        "            plt.axvline(x=self.x_right_boundary, color='r', linestyle='-')\n",
        "            \n",
        "\n",
        "            plt.xlabel('X-COORDINATE(m)')\n",
        "            plt.ylabel('Y-COORDINATE(m)')\n",
        "            plt.title('TRAJECTORY')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Function Parse Metadata. Dependency Brachistochrone Class"
      ],
      "metadata": {
        "id": "hnsFHBAILkEU"
      },
      "id": "hnsFHBAILkEU"
    },
    {
      "cell_type": "code",
      "source": [
        "def ParseMetadataFile(env_class = Brachistochrone_Env, filepath =\"\"):\n",
        "  plist= [k for k in vars(env_class) if isinstance(k, str)]\n",
        "  hyp= [elem for elem in plist if not elem.startswith('_') and not callable(getattr(Brachistochrone_Env,elem))]\n",
        "  hyp_values= [getattr(env_class,par) for par in hyp]\n",
        "  tuples = zip(hyp,hyp_values)\n",
        "  \n",
        "  with open(filepath, \"a+\") as hypdata:\n",
        "      hypdata.write(\"<<<MODEL HYPER-PARAMETERS>>>\\n\\n#env params#\\n\")\n",
        "      for strl,val in tuples:\n",
        "          nline= \"%s:%f\\n\"%(strl,val)\n",
        "          hypdata.write(nline)\n",
        "      hypdata.write(\"#wrapper params#\\n\\n\")"
      ],
      "metadata": {
        "id": "4dz-6SEtLZwe"
      },
      "id": "4dz-6SEtLZwe",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reinforcement Learning Base Solution Builder"
      ],
      "metadata": {
        "id": "HAaZa821qhp0"
      },
      "id": "HAaZa821qhp0"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "12833f5c-3c8d-4c60-b0a1-fc4635c6e0ba",
      "metadata": {
        "id": "12833f5c-3c8d-4c60-b0a1-fc4635c6e0ba"
      },
      "outputs": [],
      "source": [
        "class RLBaseSolutionBuilder:\n",
        "    \n",
        "    def __init__(self, env_class, target_pos =(8.0, -6.0) ):\n",
        "        self.target_pos = target_pos\n",
        "        self.current_model = None\n",
        "        self.current_model_name = None\n",
        "        self.env_class = env_class\n",
        "        env_class.renderOnReset= False\n",
        "        env_class.dt = 0.1 #the smaller dt is,the slower is training the agent, the higher is resolution\n",
        "\n",
        "\n",
        "    def TrainNewAgent(self,training_steps = 15000, model_name=\"test_model\", renderOnReset=False):\n",
        "        #allena un nuovo agent sul env inizializzato e lo salva se specificato con tanto di stats per la normalizzazione\n",
        "        #wrapping fro obs_space and action_space normalization\n",
        "            \n",
        "        self.current_model_name = model_name\n",
        "        SELECTED_MODEL = self.current_model_name\n",
        "        change_selected_model()\n",
        "\n",
        "        base_env = self.env_class()\n",
        "        if (renderOnReset):\n",
        "            base_env.renderOnReset=True\n",
        "        \n",
        "        self.env = make_vec_env(lambda:base_env , n_envs=1)\n",
        "    \n",
        "        self.env = VecNormalize(self.env, training=True ,norm_obs=True, norm_reward=True)\n",
        "\n",
        "        save_vec_normalize = SaveVecNormalizeCallback(save_freq=1, save_path=normalization_path)\n",
        "\n",
        "        self.learning_rate_schedule = LinearSchedule(training_steps,0.000125,0.1)\n",
        "        \n",
        "        eval_callback = EvalCallback(self.env, best_model_save_path=selected_path, callback_on_new_best=save_vec_normalize,\n",
        "                                                     log_path=log_path, eval_freq=100,\n",
        "                                                     deterministic=True, render=False)\n",
        "\n",
        "\n",
        "        self.current_model = PPO('MlpPolicy', env =self.env, verbose=0,batch_size=32, #n_steps= NSTEPS, batch_size = BATCHSIZE,\n",
        "                    gamma= 0.99, learning_rate=self.learning_rate_schedule.value,\n",
        "                    policy_kwargs= dict(net_arch=[600, 600, 300]), tensorboard_log=tensorboard_log)\n",
        "\n",
        "        print(\"training model %s start...\"%{model_name})\n",
        "        self.current_model.learn(total_timesteps=training_steps, log_interval=1, callback=eval_callback)\n",
        "        self.env.set_attr(\"renderOnReset\",False)\n",
        "        print(\"training model %s finish\"%{model_name})\n",
        "        ParseMetadataFile(self.env_class, filepath=hypdict_path)\n",
        "        \n",
        "    def LoadAgentModel(self, model_name):\n",
        "        #carica dalla memoria un agent pre-trainato\n",
        "        try:\n",
        "            base_env = self.env_class()\n",
        "            base_env.renderOnReset=False\n",
        "            self.env = make_vec_env(lambda: base_env, n_envs=1)\n",
        "            #recall statistics for normalizer\n",
        "            self.env = VecNormalize.load(stats_path, self.env)\n",
        "            \"\"\"model loading\"\"\"\n",
        "            self.current_model = PPO.load(best_model_path, env=self.env)\n",
        "            self.current_model_name= model_name\n",
        "        except:\n",
        "            print(\"no model/env found, loading failed\\n\")\n",
        "    \n",
        "    def ValidateAgent(self, save=False):\n",
        "        #esegue l'agent sull'env, costruendo e graficando la candidata base solution\n",
        "        position= [] #list of tuples containing subsequent positions\n",
        "        x = [] # x steps\n",
        "        y = [] #y values associated\n",
        "        steps = 0\n",
        "        actions = []\n",
        "        observations = []\n",
        "        episodic_reward = []\n",
        "        \n",
        "        #  do not update them at test time\n",
        "        self.env.training = False\n",
        "        # reward and input-state normalization is not needed at test time\n",
        "        self.env.norm_obs = False\n",
        "        self.env.norm_reward = False\n",
        "        \n",
        "        obs= self.env.reset()\n",
        "        while True:\n",
        "            action= self.current_model.predict(obs, deterministic = True)\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            observations.append(obs)\n",
        "            new_value = obs[0] #the array from which to extract new piece of path information\n",
        "            \"\"\"new_value[1]: pos_x new_value[2]: pos_y\"\"\"\n",
        "            position.append((new_value[0],new_value[1]))\n",
        "            if done==False:\n",
        "                x.append(new_value[0])\n",
        "                y.append(new_value[1])\n",
        "            episodic_reward.append(reward)\n",
        "            actions.append(action)\n",
        "            steps+=1\n",
        "            #print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "            if done:\n",
        "                #try:\n",
        "                    \"\"\"solution refinement\"\"\"\n",
        "                    #check for starting point, sometimes input space normalization makes it lost\n",
        "                    if (x[0]!=0 or y[0]!=0):\n",
        "                        x.insert(0,0)\n",
        "                        y.insert(0,0)\n",
        "                    plot_solution(x,y,self.target_pos,title=self.current_model_name,savef=save)\n",
        "                    print(\"Goal reached!\", \"episodic-reward=\", np.sum(episodic_reward))\n",
        "                    print(\"Steps taken: \" + str(steps))\n",
        "                    print(\"Time taken: \" , steps*self.env.get_attr(\"dt\"))\n",
        "                #except:\n",
        "                    #print(\"%s is empty\"%(self.current_model_name))\n",
        "                    break\n",
        "    \n",
        "    def GetBaseSolution(self):\n",
        "        self.solution_vector=[]\n",
        "        obs = self.env.reset()\n",
        "        while True:\n",
        "            action= self.current_model.predict(obs, deterministic = True)\n",
        "            self.solution_vector.append(action[0])\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            new_value = obs[0] #the array from which to extract new piece of path information\n",
        "            if done:\n",
        "                return self.solution_vector\n",
        "    \n",
        "    def GetEnv(self):\n",
        "        return self.env"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer Middleware Manager\n",
        "\n",
        "Middle logic class for hybrid optimizer construction\n"
      ],
      "metadata": {
        "id": "9cacX5tJrQlu"
      },
      "id": "9cacX5tJrQlu"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b87754f8-f16e-4744-88cd-67ebc4ea0c18",
      "metadata": {
        "id": "b87754f8-f16e-4744-88cd-67ebc4ea0c18"
      },
      "outputs": [],
      "source": [
        "class OptimizerMiddlewareManager:\n",
        "    #acts on standard deviation for gaussian random variable sampling [0;1]\n",
        "    amountOfVariation = 0.05 #FOR CAST SOLUTIONS [0;0.1], FOR BASE SOLUTION [0;1]\n",
        "    def __init__(self,env,base_solution, pop_size=100):\n",
        "        self.env = env\n",
        "        self.pop_cardinality = pop_size\n",
        "        self.base_solution = base_solution\n",
        "        self.discretizer = env.get_attr(\"action_discretizer\")[-1]\n",
        "        self.amountOfVariation = OptimizerMiddlewareManager.amountOfVariation\n",
        "    def base_solution_cast(self):\n",
        "        #method needed for domain adaptation\n",
        "        obs = env.reset()#reset the whole environment\n",
        "        self.cast_base_solution = []\n",
        "        for action in self.base_solution:\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            new_value = obs[0] #the array from which to extract new piece of path information\n",
        "            if done==False:\n",
        "                self.cast_base_solution.append((new_value[0],new_value[1]))\n",
        "\n",
        "            if done:\n",
        "                try:\n",
        "                    #check for starting point, sometimes input space normalization makes it lost\n",
        "                    if (self.cast_base_solution[0]!=(0.0,0.0)):\n",
        "                        self.cast_base_solution.insert(0,(0.0,0.0))\n",
        "                    return self.cast_base_solution\n",
        "                except:\n",
        "                    print(\"WARNING : empty model\\n\")\n",
        "                break\n",
        "\n",
        "                    \n",
        "    def NoiseApply(self,pop_ind_value, castedversion=False):\n",
        "        #print(pop_ind_value)\n",
        "        if (castedversion):\n",
        "            noise = random.gauss(0,self.cast_sigma)\n",
        "            return np.array([pop_ind_value[0],pop_ind_value[1]+noise])\n",
        "            \n",
        "        else:\n",
        "            noise = random.gauss(0,self.sigma)\n",
        "            pop_ind_value = np.array([self.discretizer(pop_ind_value+noise)])\n",
        "        return pop_ind_value\n",
        "\n",
        "    def InitialPopulationCreator(self, amntOfVar=None):\n",
        "        if amntOfVar is not None:\n",
        "            self.amountOfVariation = amntOfVar\n",
        "        #building variation around candidate optimal solution to feed next evolutionary optimizer\n",
        "        init_population = []\n",
        "        self.sigma = (max(self.base_solution)- min(self.base_solution))[0]*(self.amountOfVariation)\n",
        "        for i in range(self.pop_cardinality):\n",
        "            elem_sol=list(map(self.NoiseApply,self.base_solution))\n",
        "            init_population.append(elem_sol)\n",
        "        init_population = np.array(init_population)\n",
        "        self.init_population = init_population\n",
        "        return init_population\n",
        "    \n",
        "    def InitialPopulationRender(self):\n",
        "        #warning: some randomly built solutions could be not feasible and eventually not renderizable\n",
        "        try:\n",
        "            for sol in self.init_population:\n",
        "                obs = env.reset()#reset the whole environment\n",
        "                x=[]\n",
        "                y=[]\n",
        "                for action in sol:\n",
        "                    obs, reward, done, info = env.step(action)\n",
        "                    new_value = obs[0] #the array from which to extract new piece of path information\n",
        "                    if done==False:\n",
        "                        x.append(new_value[0])\n",
        "                        y.append(new_value[1])\n",
        "                    if done:\n",
        "                        try:\n",
        "                            #check for starting point, sometimes input space normalization makes it lost\n",
        "                            if (x[0]!=0 or y[0]!=0):\n",
        "                                x.insert(0,0)\n",
        "                                y.insert(0,0)\n",
        "                            \"\"\"data visualization\"\"\"\n",
        "                            plot_solution(x,y,goal,title=\"CANDIDATE SOLUTION\",savef=False)\n",
        "                        except:\n",
        "                            print(\"WARNING : empty model\\n\")\n",
        "                        break \n",
        "        except:\n",
        "                print(\"error: no InitialPopulation was initialized\\n\")\n",
        "                \n",
        "    def TranslatedPopulationRender(self):\n",
        "        try:\n",
        "            for XYpairs in self.cast_pop:\n",
        "                Xs,Ys = zip(*XYpairs)\n",
        "                plt.plot(Xs,Ys,label= \"variated solution in translated domain\")\n",
        "                plt.scatter(Xs[-1], Ys[-1], color = 'green', s = 100.0)\n",
        "                plt.scatter(Xs[0], Ys[0], color = 'red', s = 100.0)\n",
        "                plt.annotate('Start', (Xs[0], Ys[0]))\n",
        "                plt.annotate('End', (Xs[-1], Ys[-1]))\n",
        "                plt.axhline(y=self.env.get_attr(\"y_lower_boundary\"), color='r', linestyle='-')\n",
        "                plt.axvline(x=self.env.get_attr(\"x_right_boundary\"), color='r', linestyle='-')\n",
        "                plt.show()\n",
        "        except:\n",
        "            print(\"error: no cast population was initialized, call CreatePopInTranslatedDomain method\\n\")\n",
        "    \n",
        "    def ExportPopulationToCSV(self, folder=selected_path, file='data.csv'):\n",
        "      file = os.path.join(folder, file)\n",
        "\n",
        "      try:\n",
        "          # solution numpy array is shaped pop_cardinality * sol_lenght * 1(single-alement-array for single action modleing)\n",
        "          self.init_population = np.array([np.array([x[0] for x in elem]) for elem in self.init_population])\n",
        "      except:\n",
        "          print(\"error: no InitialPopulation was initialized\\n\")\n",
        "      \n",
        "      np.savetxt(file, self.init_population,fmt='%10.3f', delimiter=\",\")\n",
        "\n",
        "\n",
        "    def ImportPopulationFromCSV(self, folder=selected_path, file='data.csv'):\n",
        "      file = os.path.join(folder, file)\n",
        "\n",
        "      try:\n",
        "          #data are deserialized to 2d dimension and not 3d, as RL agent asks, cause we intend to exploit data in next step of optimiz. pipeline\n",
        "          self.init_population = np.genfromtxt(file, delimiter=',')\n",
        "          #for elem_sol in self.init_population:\n",
        "          self.init_population = [ [np.array([varr]) for varr in elem_sol] for elem_sol in self.init_population ]\n",
        "      except:\n",
        "          print(\"error: init file not found or not accessible\\n\")\n",
        "            \n",
        "    def CreatePopInTranslatedDomain(self, amntOfVar=None):\n",
        "        #take an initial solution in delta angle domain and creates (x,y) pairs individuals\n",
        "        if amntOfVar is not None:\n",
        "            self.amountOfVariation = amntOfVar\n",
        "        self.cast_pop=[]\n",
        "        try:\n",
        "            _, y_values = zip(*self.cast_base_solution)\n",
        "            self.cast_sigma = (max(y_values)- min(y_values))*(self.amountOfVariation)\n",
        "            for i in range(self.pop_cardinality):\n",
        "                #elem_sol = [np.array([varr[0],varr[1]+noise]) for varr in self.cast_base_solution]\n",
        "                elem_sol=list(map(self.NoiseApply,self.cast_base_solution,np.full(len(self.cast_base_solution),True)))\n",
        "                elem_sol.insert(0,np.array([0.0,0.0]))\n",
        "                elem_sol.append(tuple(self.env.get_attr(\"target_pos\")[0]))\n",
        "                self.cast_pop.append(elem_sol)\n",
        "\n",
        "            cast_population = np.array(self.cast_pop)\n",
        "            self.cast_pop = cast_population\n",
        "            return cast_population\n",
        "        except:\n",
        "            print(\"error: no cast base solution was initialized, call base_solution_cast method\\n\")\n",
        "    \n",
        "    def GetInitPopData(self):\n",
        "        try:\n",
        "            \"\"\"return initial pop, pop cardinality and gene size for MOEA\"\"\"\n",
        "            return self.cast_pop, self.cast_pop.shape[0], self.cast_pop.shape[1]\n",
        "        except:\n",
        "            print(\"error: no cast population was initialized, call CreatePopInTranslatedDomain method\\n\")\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Section Reinforcement Learning"
      ],
      "metadata": {
        "id": "H2PeQs23rbXs"
      },
      "id": "H2PeQs23rbXs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation of new Training Set (3 Generations)"
      ],
      "metadata": {
        "id": "KbBBeJ39tba_"
      },
      "id": "KbBBeJ39tba_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d731ab-9b9b-4ee8-9970-4e20fa023d0a",
      "metadata": {
        "tags": [],
        "id": "f3d731ab-9b9b-4ee8-9970-4e20fa023d0a"
      },
      "outputs": [],
      "source": [
        "#grid hyperparametrization\n",
        "for Brachistochrone_Env.active_friction in [True,False]:\n",
        "    for Brachistochrone_Env.dt in [0.1,0.2]:\n",
        "        for Brachistochrone_Env.init_angle in [-90,-65]:\n",
        "            for Brachistochrone_Env.sol_space_padding in [1.5,2.5]:\n",
        "                for Brachistochrone_Env.action_space_padding in [2.0,3.0]:\n",
        "                    \"\"\"HYP FOR AGENT TRAINING\"\"\"\n",
        "                    goal = (8.0, -6.0)\n",
        "                    SELECTED_MODEL = 'generalized_final_3G_nrn_2_'+str(Brachistochrone_Env.active_friction)+'_'+str(Brachistochrone_Env.dt)+'_'+str(Brachistochrone_Env.init_angle)+'_'+str(Brachistochrone_Env.sol_space_padding)+'_'+str(Brachistochrone_Env.action_space_padding)\n",
        "                    change_selected_model()\n",
        "\n",
        "                    TOT_STEPS = 150000\n",
        "                    Brachistochrone_Env.renderOnReset= False\n",
        "                    \"\"\"\"\"\"\"\"\"\"\"\"\n",
        "                    env = Brachistochrone_Env()\n",
        "                    learning_rate_schedule = LinearSchedule(TOT_STEPS,0.000125,0.1)\n",
        "                    print(env.target_pos)\n",
        "                    env = make_vec_env(lambda: env, n_envs=1)\n",
        "\n",
        "                    #wrapping fro obs_space and action_space normalization\n",
        "                    env = VecNormalize(env, training=True ,norm_obs=True, norm_reward=False)\n",
        "                    #callback initialization for online update of normalization stats\n",
        "                    save_vec_normalize = SaveVecNormalizeCallback(save_freq=1, save_path=normalization_path)\n",
        "\n",
        "\n",
        "                    eval_callback = EvalCallback(env, best_model_save_path=selected_path, callback_on_new_best=save_vec_normalize,\n",
        "                                                 log_path=log_path, eval_freq=500,\n",
        "                                                 deterministic=True, render=False)\n",
        "                    #PPO algorithm is made to discourage radical changes of the policy among differrent episodes, this makes the algorithm more sensible to local minima\n",
        "                    #provare altri algoritmi PPo2, ACKTR\n",
        "                    model = PPO('MlpPolicy', env =env, verbose=0,\n",
        "                                gamma= 0.99, learning_rate=learning_rate_schedule.value,\n",
        "                                policy_kwargs= dict(net_arch=[600, 600, 300]), tensorboard_log=tensorboard_log)\n",
        "\n",
        "\n",
        "                    model.learn(total_timesteps=TOT_STEPS, log_interval=1, callback=eval_callback)\n",
        "                    #build metadata\n",
        "                    metad = ParseMetadataFile(env_class = Brachistochrone_Env,filepath=hypdict_path)\n",
        "\n",
        "                    print(\"<<<END OF %s MODEL TRAINING>>>\"%(SELECTED_MODEL))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automation Test Results for Normalized input and Rewards"
      ],
      "metadata": {
        "id": "Uiroy7OgsUJQ"
      },
      "id": "Uiroy7OgsUJQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b71dc67-730a-4fa9-9fad-6be7d8c804ce",
      "metadata": {
        "tags": [],
        "id": "2b71dc67-730a-4fa9-9fad-6be7d8c804ce"
      },
      "outputs": [],
      "source": [
        "#grid hyperparametrization\n",
        "for Brachistochrone_Env.active_friction in [True,False]:\n",
        "    for Brachistochrone_Env.dt in [0.1,0.2]:\n",
        "        for Brachistochrone_Env.init_angle in [-90,-65]:\n",
        "            for Brachistochrone_Env.sol_space_padding in [1.5,2.5]:\n",
        "                for Brachistochrone_Env.action_space_padding in [2.0,3.0]:\n",
        "                    goal = (8.0, -6.0)\n",
        "                    SELECTED_MODEL = 'generalized_final_3G_nrn_2_'+str(Brachistochrone_Env.active_friction)+'_'+str(Brachistochrone_Env.dt)+'_'+str(Brachistochrone_Env.init_angle)+'_'+str(Brachistochrone_Env.sol_space_padding)+str(Brachistochrone_Env.action_space_padding)\n",
        "                    change_selected_model()\n",
        "\n",
        "                    #building found optimal path\n",
        "                    Brachistochrone_Env.renderOnReset=False\n",
        "                    env = Brachistochrone_Env()\n",
        "                    env = make_vec_env(lambda: env, n_envs=1)\n",
        "                    \"\"\"load stats and env config\"\"\"\n",
        "                    try:\n",
        "                        #recall statistics for normalizer\n",
        "                        env = VecNormalize.load(stats_path, env)\n",
        "                        #  do not update them at test time\n",
        "                        env.training = False\n",
        "                        # reward and input-state normalization is not needed at test time\n",
        "                        env.norm_obs = False\n",
        "                        env.norm_reward = False\n",
        "                        \"\"\"model loading\"\"\"\n",
        "                        model = PPO.load(best_model_path, env=env)\n",
        "                    except:\n",
        "                        print(\"no model found\")\n",
        "                        continue\n",
        "\n",
        "                    position= [] #list of tuples containing subsequent positions\n",
        "                    x = [] # x steps\n",
        "                    y = [] #y values associated\n",
        "                    steps = 0\n",
        "                    actions = []\n",
        "                    observations = []\n",
        "                    #BUILD SOLUTION\n",
        "                    #print(\"Episode {}\".format(ep + 1))\n",
        "                    episodic_reward = []\n",
        "\n",
        "\n",
        "                    #we have to force target into environment as it must be constant and specified to AI agent\n",
        "\n",
        "                    obs = env.reset()\n",
        "                    print(\"Inital obs: \"  +str(obs))\n",
        "\n",
        "                    \"\"\"SOLUTION RECONSTRUCTION\"\"\"\n",
        "                    while True:\n",
        "                        action= model.predict(obs, deterministic = True)\n",
        "                        obs, reward, done, info = env.step(action)\n",
        "                        observations.append(obs)\n",
        "                        new_value = obs[0] #the array from which to extract new piece of path information\n",
        "                        \"\"\"new_value[1]: pos_x new_value[2]: pos_y\"\"\"\n",
        "                        position.append((new_value[0],new_value[1]))\n",
        "                        if done==False:\n",
        "                            x.append(new_value[0])\n",
        "                            y.append(new_value[1])\n",
        "                        episodic_reward.append(reward)\n",
        "                        actions.append(action)\n",
        "                        steps+=1\n",
        "                        #print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "                        if done:\n",
        "                            try:\n",
        "                                \"\"\"solution refinement\"\"\"\n",
        "                                #clean last step from the history\n",
        "                                x.pop()\n",
        "                                y.pop()\n",
        "                                position.pop()\n",
        "                                #check for starting point, sometimes input space normalization makes it lost\n",
        "                                if (x[0]!=0 or y[0]!=0):\n",
        "                                    x.insert(0,0)\n",
        "                                    y.insert(0,0)\n",
        "                                print(x)\n",
        "                                print(y)\n",
        "                                plot_solution(x,y,goal,title=SELECTED_MODEL,savef=True)\n",
        "                                print(\"Goal reached!\", \"episodic-reward=\", np.sum(episodic_reward))\n",
        "                                print(\"Steps taken: \" + str(steps))\n",
        "                                print(\"Time taken: \" , steps*Brachistochrone_Env.dt)\n",
        "                            except:\n",
        "                                print(\"%s is empty\"%(SELECTED_MODEL))\n",
        "                            break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Pipeline for Integration with Genetic Algorithm"
      ],
      "metadata": {
        "id": "qmramQodrwKH"
      },
      "id": "qmramQodrwKH"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "642e5d3b-877f-4f98-9422-d851dbc911a6",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "642e5d3b-877f-4f98-9422-d851dbc911a6",
        "outputId": "bdb20108-22f5-4d3b-80aa-d449a0151fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no model/env found, loading failed\n",
            "\n",
            "training model {'pipeline_test'} start...\n",
            "Eval num_timesteps=100, episode_reward=-52.49 +/- 0.02\n",
            "Episode length: 19.00 +/- 0.00\n",
            "New best mean reward!\n",
            "Eval num_timesteps=200, episode_reward=-52.53 +/- 0.06\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=300, episode_reward=-57.58 +/- 0.01\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=400, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=500, episode_reward=-57.71 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=600, episode_reward=-57.71 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=700, episode_reward=-57.71 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=800, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=900, episode_reward=-57.71 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=1000, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1100, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1200, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1300, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1400, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1500, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1600, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1700, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1800, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=1900, episode_reward=-52.71 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=2000, episode_reward=-52.77 +/- 0.00\n",
            "Episode length: 19.00 +/- 0.00\n",
            "Eval num_timesteps=2100, episode_reward=-67.85 +/- 0.00\n",
            "Episode length: 17.00 +/- 0.00\n",
            "Eval num_timesteps=2200, episode_reward=-67.85 +/- 0.00\n",
            "Episode length: 17.00 +/- 0.00\n",
            "Eval num_timesteps=2300, episode_reward=-67.85 +/- 0.00\n",
            "Episode length: 17.00 +/- 0.00\n",
            "Eval num_timesteps=2400, episode_reward=-64.23 +/- 1.81\n",
            "Episode length: 17.80 +/- 0.40\n",
            "Eval num_timesteps=2500, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=2600, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=2700, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=2800, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=2900, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3000, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3100, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3200, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3300, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3400, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3500, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3600, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3700, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3800, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=3900, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=4000, episode_reward=-63.33 +/- 0.00\n",
            "Episode length: 18.00 +/- 0.00\n",
            "Eval num_timesteps=4100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=4900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=5900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=6900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=7900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=8900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=9900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=10900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=11900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=12900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=13900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=14900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15400, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15500, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15600, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15700, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15800, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=15900, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=16000, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=16100, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=16200, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "Eval num_timesteps=16300, episode_reward=-54.23 +/- 0.00\n",
            "Episode length: 20.00 +/- 0.00\n",
            "training model {'pipeline_test'} finish\n",
            "Time taken by cycloid =  1.5910103093924441\n",
            "Time taken by linear solution =  1.8257418583505538\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3yO1//H8de5s6eR2ERISIkRYm+lGjOxtbRWqyhtaRXVEqqtoqhqjV8VNatGgpo1ao9EY8UmNokgU/b5/XFHvmhk37kyzvPxuB+9x3Wd630r+eS6znXOEVJKFEVRFOVlOq0DKIqiKHmTKhCKoihKqlSBUBRFUVKlCoSiKIqSKlUgFEVRlFSpAqEoiqKkShUIpcAQQjQXQlzMobaChBBtk59/IYT4NSfaVZT8RKhxEIryX0KIIOA9KeXfuXAsR+A6YCKlTMhmW0uB21LKL7OfTCns1BmEoiiKkipVIJR8J/nyz3ghRKAQ4rEQYokQwlwI0UoIcTu97Z77vJMQIkAI8UQIcVgIUesVx/MWQqxIfu4ohJBCiP5CiJtCiIdCiAnPbasTQowTQlwVQoQKIdYKIYqn85X2J//3iRAiUgjROLmtQUKI88nZdwghKia/L4QQs4UQwUKIcCHEGSFEDSHEEKAv8HlyO5uz8uerKM+oAqHkV32BNwEnoCrwqksqqW4nhKgD/AZ8ANgBC4FNQgizDB6/GeACtAEmCiGqJb8/EvACWgJlgcfAz+m01SL5v0WllNZSyiNCCE/gC6AbUAI4AKxO3q5d8j5VgSJALyBUSrkIWAlMT26ncwa/i6KkShUIJb+aJ6W8JaV8BHwDvJXJ7YYAC6WUx6SUiVLKZUAs0CiDx58spXwqpTwFnAJqJ78/FJggpbwtpYwFvIEeQgjjTH6/ocB3Usrzyf0S3wJuyWcR8YAN8Br6fsTzUsp7mWxfUdKlCoSSX9167vkN9L+tZ2a7isCnyZeXngghngAV0mjnZfefex4NWD/X7sbn2jwPJAKlMtjuMxWBH59r5xEggHJSyj3APPRnJsFCiEVCCNtMtq8o6VIFQsmvKjz33AG4m8ntbgHfSCmLPvewlFKu/m8TmXILaP9Su+ZSyjtp7JParYS3gA9easdCSnkYQEo5V0rpDlRHf6lpTBptKUqWqAKh5FcfCiHKJ3cATwD+yOR2/wcMFUI0TO70tRJCdBRC2GQz1wLgm+c6lEsk9yekJQRIAiq/1M54IYRrcjtFhBA9k5/XT85tAkQBMcn7Azx4qR1FyTJVIJT8ahWwE7gGXAWmZmY7KaUf8D76SzWPgSvAgBzI9SOwCdgphIgAjgIN09pBShmNvn/kUPIlpUZSyo3A98AaIUQ4cBZon7yLLfoC9xj9ZbNQYEbyZ4uB6snt+OTA91EKMTVQTsl3MjqILTcHuylKQaTOIBRFUZRUqQKhKLlACNE3efDay49zWmdTlFdRl5gURVGUVKkzCEVRFCVVmR3dqSl7e3vp6OiodQxFUZR8xd/f/6GUskRm98tXBcLR0RE/Pz+tYyiKouQrQogbWdlPXWJSFEVRUlXoCsQ333yDq6srtWrVws3NjWPHjjFnzhyio6Mz3dbSpUu5e/dVMzwoiqLkb4WqQBw5coQtW7Zw8uRJTp8+zd9//02FChWyVCASExNVgVAUpUAr2AXi6lUYPhxsbUGn497rr2N/7x5mt/Vrytjb27Nu3Tru3r1L69atad26NQDDhg2jXr16uLq6MmnSpJTmHB0dGTt2LHXr1mX16tX4+fnRt29f3NzcePr0qSZfUVEUxWCklPnm4e7uLjNs61YpLS2lNDGREqQEGQGyNsgqQshhHTvKffv2SSmlrFixogwJCUnZNTQ0VEopZUJCgmzZsqU8depUynbff/99ynYtW7aUJ06cyHgmRVEUDQB+Mgs/czU9gxBCeAghLgohrgghxuVYw1evQo8eEB0N8fEpb1sD/sAiKSmxYwe9e/Rg6dKl/9l97dq11K1blzp16nDu3DkCAwNTPuvdu3eOxVQURcnLNLvNVQhhhH7BkzeA28AJIcQmKWVg2ntmwA8/vFAYnmcEtAJaCUFNd3eWrV//wufXr19n5syZnDhxgmLFijFgwABiYmJSPreyssp2PEVRlPxAyzOIBsAVKeU1KWUcsAZIb978jFmx4oUC8UfP1/h6bG0CgcvP3oyPJ2DvXipWrIiNjQ0REREAhIeHY2VlRZEiRXjw4AHbtm175WGe309RFKWg0XKgXDleXA7yNqnMmy+EGIJ+/WAcHBwy1nJk5AsvD9UxZW/ZRA69V57gZXeIiZcYA85xcSzy9mb16tV4eHhQtmxZ9u7dS506dXjttdeoUKECTZs2feVhBgwYwNChQ7GwsODIkSNYWFhkLJ+iKEo+oNlkfUKIHoCHlPK95NfvAA2llCNetU+9evVkhkZS29rCc7/ZX+1aicDGMXxjZUecaRJDNocw+K+HmFjZQFhYtr+LoihKXiaE8JdS1svsflpeYrrDi+sFl09+L/v69QMTk5SX5W4+oHNUFF13V6Otfzg/dytFH28nzn3glSOHUxRFKYi0LBAngCpCiEpCCFOgD/qlGrPv009fKBDmD2IBCHaoyLQFd5g75wZPbIx52zWAWX6zeJqgxjAoiqK8TLMCIaVMAEYAO4DzwFopZc4snuLkBOvWgaWlvlA8TASgmGUUAQ7VaX0pkY3O39C1SleWnFtCj009OHH/RI4cWlEUpaDQdByElHKrlLKqlNJJSvlNjjbevj2cPg1DhoCpLUlRkqrcZmv3oXD6NLYdu+HdxJtf2/1Kkkxi0I5BfH3kayLjItNvW1EUpRAo2FNtODnBvHkQFoauVhuaWN5krW0VHpf+X9dHwzIN2eC5gXerv8u6y+vw8vVi/+39GoZWFEXJGwp2gXieYzPKx1/HNPYRP+6+/MJHFsYWjKk/huXtl2NjasOHuz9k3IFxPI55rFFYRVEU7RWiAtEcgNFVQ1h+9AZXgv97KalWiVqs7bSW4bWHsyNoB54+nmy7vg2tbgVWFEXRUuEpEGXrgIkVXYtdx8LEiO+2nk91MxMjE4a5DWNtp7WUtynP5/s/56M9H/Eg6kEuB1byIiMjI9zc3FIe06ZNy9T+jo6OPHz40EDpFCVn5aslR7PFyAQcGmFx5zAfth7B99svcPDyQ5pVsU918yrFqrC8/XJWnF/BvH/n4eXrxaf1PqV7le4IIXI5vJJXWFhYEBAQoHUMRckVhecMAqBScwi5wEA3K8oXs2DqX4EkJr368pGRzoj+rv3Z0GUD1e2qM/nIZN7b+R63wm+9ch+lYLn66CrD/xqO7Xe26CbriIqPYvhfw7n66OoL2zk6OjJp0iTq1q1LzZo1uXDhAgChoaG0a9cOV1dX3nvvPXW5UslXCleBSO6HML99iPHtq3HhfgRLDl1Pd7cKthX4td2vTGo8icDQQLpt6sayc8tITEo0dGJFQ9sub6PWglr8evJXIuIikEiIh/nvzaeKaxWcqjnxxx9/pGxvb2/PyZMnGTZsGDNnzgRg8uTJNGvWjHPnztG1a1du3ryp1ddRlEwrXAWijBtY2kOgLx1qlqZttVJ8u/U8uwLT718QQtCjag98PH1oVKYRM/1m8s62d7j8+HK6+yr5z9VHV+nxZw+i46OJT3pu6nhjYCjIoZL779yn3hv/m96mW7duALi7uxMUFATA/v376devHwAdO3akWLFiufUVFCXbCleBMDKGGt3g4nZEbARz33KjZrkijFx9kn9vZuyW1lJWpZj7+lxmtJjBncg79NrSi/kB84lPTH39CSV/+uHID+n+P41PjGf20dkpr83MzAB9R3ZCQoJB8ylKbihcBQKgZi9IjIXzm7E0NebX/vUpYWPGe8v8uBEalaEmhBB4VPLAx9OHNx3f5JdTv9BrSy/OhJwxcHglt6w4veJ/Zw4SLBNaIOSL07nHJ8Wz/PTyNNtp0aIFq1atAmDbtm08fqzG1ij5R+ErEOXrQbFKcGYtACVszFg6sAGJUjJgyQkeRcVluKli5sWY1nwaP7f5mYi4CPpt68eMEzPU5H8FwLMpV3TSlhJxX1Ai/nNsEjpAAjD/f4/wv8LTbGfSpEns378fV1dXNmzYkPE1TRQlD9BsPYisyPB6EOnZ8w0cmAmjz4NNaQD8bzzi7f87hmtZW1a93whzE6NMNRkZF8ls/9msvbSW8tblmdxkMg3KNMh+VkUTtt/akvS0PsXi30OHBU+Mfyfc2AfEi/9ebM1sCRun1hRR8rb8uB6Edmr1ApkEZ/+3HrV7xeL82MeNf2894eM1/6Z5+2tqrE2t+arxV/z25m/ohI7BOwfjfdibiDi1JGl+cyM0iiq6n7CPH0287jb3zD4m3GTjf4qDic6Ed2q9o1FKRTG8wlkg7Kvo72g6vfaFtz1qlOGrjtXZce4BX28JzNI96/VL12ddl3UMdB3Ixisb8fLxYt+tfTkUXDGksKfxfLftPG/M3s/T6JJEmP8fD0zHEq9L/dZUEyMTRjUalcspFSX3FM4CAfqziHsB8PDF21QHNavE4GaVWHo4iM/+PE10XObvRrEwtmB0vdGs6rCKIuZFGLlnJJ//8zmPYh7lVHolB8UmJPLrgWu0nLGXRfuv0alWGfZ82poVfT/A0tQCE53JC9ub6EywNLFkXc91OBV30ii1ohhe4eyDAIi4D7OqQfPP4PUJL3yUlCT5cfdl5u65TJWS1vzSty7OJW2ydJj4xHgWn13MwtMLsTaxZlyDcXSo1EFN15EHJCVJNp++y4wdF7n9+CnNq9gzrv1ruJYtkrLN1UdXmX10NstPLycyLhJrU2veqfUOoxqNUsVByTey2gdReAsEwO9e+jOIjwP0czW95MDlED5ZE8DT+ES+61YTT7dyWT7UlcdXmHRkEqdDTtOifAu+avQVpa1KZye9kkVxCUlsPnWXRfuvcfFBBNXL2DK+w2s0r1JC62iKYhCqQGTFpR2wqhd0XQi1+6S6yf2wGEauPsmJoMf0bejAV52qZ/oOp2cSkxJZfWE1c/+di07oGO0+mh5Ve6AThfdKX26KjE1gzfGbLD54nXthMbiUsmFYKye61C6LTqfO6JSCSxWIrJAS5jfRPx92GF5x2SchMYmZOy+x4J+ruJa15Ze+daloZ5Xlw96KuMXkI5M5du8Y9UrVw7uJNxVtK2a5PSVtweExLDkcxIqjN4iISaBR5eJ80NKJVlVLqEt9SqGgCkRWnVoDGz+At9dC1TfT3HT3+QeMXnuKpCTJjJ618KhRJsuHlVLic8WHGSdmEJcUx4duH/JO9Xcw1hWeGdgNSUrJmTthrDx6k43/3iE+KYn2NUozpIUTbhWKah1PUXKVKhBZlRgPc+tAkQowaFu6m99+HM2Hq/7l1K0nDGpaiXHtX8PUOOuXiIKjg5l6dCp7b+3F1c6VyU0m41LcJcvtFXYPI2Px+fcOf/rd5uKDCMyMdfRwL8/7zSvjaJ/1sz5Fyc9UgciOo/Nh+zgYvAsqpD/6OS4hiW+3nmfp4SBqVyjKVx2rUc+xeJYPL6Vk542dfHvsW8JjwxlcczBDag3B1Mg0y20WJvGJSey9EMyf/rfZeyGYhCRJ7QpF6elens61y1LE4r83IChKYaIKRHbERcFsV3BoAm+tyvBuW8/c4yufs4RGxdHEyY6P2lShUWW7LMd4EvOE6Sems/naZpyKODG56WRql6id5fYKuov3I/jT7xY+AXd4GBmHvbUZ3eqWo4d7eaqWytptyYpSEKkCkV17v4V/vocPj0OJjF/iiY5LYNWxmyz45xoPI2NpUKk4H7epQhMnuyx3gB64fYApR6fwIOoBfav1ZWSdkViaWGaprYJESsnZO+H8ff4BuwIfEHgvHGOdoE21kvR0r0BLlxKYGKk7whTlZfmqQAghegLeQDWggZQyQz/1DVogokL1ZxE1uoPXz5nePSY+kdXHb7Lgn6s8CI/FvWIxPmpThRZV7LNUKKLio5jjP4c1F9dQzrockxpPonHZxpluJ7+LiU/k8NWH/H0+mN3nH/AgPBadgLoOxfCoURqvOuWwtzbTOqai5Gn5rUBUA5KAhcBneaJAAGwdA35L4ONTUCRrg+Ji4hP50/828/de4W5YDLXLF+GjNlV4/bWSWSoU/g/8mXR4EjfCb9DVuSuf1f8MW1PbLGXLL0IiYtlz4QF/nw/m4OWHPI1PxMrUiBZVS9CmWilau5TAThUFRcmwfFUgUg4uxD7yUoF4fEN/R1OjYfDmN9lqKi4hifUnb/Pz3ivcfvwU17K2fNSmCm9UK5XpQVkxCTEsOLWApeeWUty8OBMaTaCNQ5ts5ctLnsYlcur2E05cf8TuC8Gcuv0EKaFsEXPaVi9Fm2qlaFS5OGbGWRugqCiFXYEtEEKIIcAQAAcHB/cbN24YNtT69+DiNhh1Fiyyv35wfGISG/+9w897r3AjNJrXStswqGklWrmUoKSteabaCgwNZNLhSVx4dIF2FdsxvuF47C3ss50xt90Pi8H/xmP8bjzi5I3HnLsbTkLy9Oq1yxehbTV9UahWxkYNZFOUHJDnCoQQ4m8gtcmGJkgpfZO32UdeOoMAeHAO5jeFxh9m+yzieQmJSWw+fZef9lzhWoh+adNqZWxpWbUELaraU69i8QyNp4hPimfp2aXMPzUfSxNLxtYfS6fKnfLsD9LEJMmF++H6ghD0GP8bj7nzRL/inrmJjtrli+JesRj1HItR16EYRS3Vrb2KktPyXIHI0MHzYoEA2DQSAlbpp9/IxB1NGZGUJDl/P5z9lx7yz6Vg/G88Jj5RYmVqRGMne1pWtadl1ZI42KV919K1sGtMOjSJgJAAmpZryqRGkyhjnfWR3TkhMjaBq8GRXAmO5EpIJGduh/HvzcdExSUCUNLGjHqOxXCvWJx6FYtRvaytuutIUXKBKhA5KTIEfnLXr1/db/0r52jKkUPFJnDkaij/XArmn0sh3Hqk/+26kr0VLarY09KlBI0q22Fp+t8pOJJkEqsvrObHkz8iEHzi/gm9XXobdPI/KSUhEbFcCYlMKQZXQ6K4EhzJ/fCYlO2MdQLnktbUcyxGvYrFca9YjPLFLPLsmY6iFGT5qkAIIboCPwElgCdAgJQy7YmQyMUCAXDkF9gxHt5aAy7tc+WQUkqCQqP552Iw+y8/5MjVUJ7GJ2JqpKN+pWI0cbKnXFELStiYYW9tRgkbM4pamHAv+i6TD0/myL0j1C1ZF+8m3lQqUinLGcKexvMwMpaQiDgeRsZy58lT/VlBcCRXQyKJiPnfIkpWpkY4lbTGuYQ1TiWtcSphjXNJaxyKW2ZrChJFUXJOvioQWZWrBSIxXt8XkRgHHx4D49y/rTImPhG/oMfsvxzCPxdDuPjgv+tbG+sEdtam2NuYorP2547uDxKJo3Hxt/Co0JtSNlaUsDHD1tyYx9H6H/z6H/6xPIyMS3n9MDKWhxFxhEbFEp/4378TJW3MUn74O5WwwrmkDU4lrShta67OChQlj1MFwhCu7IYV3aCtNzTTfu3h8Jh4QiKe/XCP/c/zh5FxPIgKIdJ6LUY2Z0mMKUvM3e4kxaY+psPESGBnZYa9jSn21mbPPUxTzlLsrc0oXcRczWekKPlYVguEmls6Lc5twKUD7J8Jtd8CG21XgLM1N8HW3ASnEtZpbpeU5IXv5e3MOjmNcPOfaV6yF+62PbG3tk6+NKUvCEUsTNRv/4qivJK6SJyeN7/RX2b621vrJBmm0wm6urRnS7dNdHbqzD/Ba9gQ/CnlyzygsZMdziVtKGppqoqDoihpUgUiPcUr68dEnFoNt3Px8lYOKGJWhKnNprKw7ULiEuPov60/3x37juj4aK2jKYqSD6gCkRHNPwXr0vq5mpKStE6TaU3KNWGj50bervY2qy+sxsvXi0N3DmkdS1GUPE4ViIwws4E3JsPdk/oziXzI0sSScQ3Gsaz9MsyNzRn691AmHJxAWGyY1tEURcmjVIHIqJq9oHx9fV9ETLjWabKsTsk6/Nn5T96v+T5/XfsLTx9Pdt3YpXUsRVHyIFUgMkqng/bfQ1Qw7J+hdZpsMTMy46O6H7Gm0xpKWpZk9L7RjNo7ipDoEK2jKYqSh6gCkRnl3MGtn34N6+DzWqfJtteKv8aqjqv4pO4n7L+9H09fT3yu+JCfxsYoimI4qkBkVltvMC8C69+HhFit02Sbsc6YwTUHs77LeqoUrcJXh77ig10fcCfyjtbRFEXRmCoQmWVdAjx/hgdnYPcUrdPkGMcijizxWMKEhhM4FXKKrr5dWXl+JYlJiVpHUxRFI6pAZIWLB9QbDEfmwdW9WqfJMTqho89rffDx9KFuqbpMOz6NAdsHcO3JNa2jKYqiAVUgsqrdVLCvChuHQvQjrdPkqDLWZZjfZj7fNvuW6+HX6bG5B4tOLyI+KV7raIqi5CJVILLK1BK6/wrRofoFhgpYx64Qgs5OnfHx9OF1h9f56d+feGvLWwSGBmodTVGUXKIKRHaUqQ1tJsKFLXDyd63TGIS9hT0zW85kTus5hMaE8vZfbzPbfzYxCTHp76woSr6mCkR2NR4BlVrA9nHw8IrWaQymjUMbfDx98HT25Lezv9Fzc0/8H/hrHUtRFANSBSK7dDrouhCMTGH9YEiI0zqRwRQxK8LkJpNZ9Ia+P2LA9gFMPTqVqPgoraMpimIA6RYIIUR5IcRnQghfIcQJIcR+IcQvQoiOQhhw8eP8xLYsdJkL9wJg33dapzG4xmUbs6HLBvpV68fai2vx8vXiwO0DWsdSFCWHpfkDXgixBPgNiAO+B94ChgN/Ax7AQSFEC0OHzBeqe0Kdd+DgbAgq+DOlWppYMrbBWJZ3WI6VsRXDdw/niwNf8CTmidbRFEXJIWkuOSqEqCGlPJvG56aAg5QyVy6+5/qSo5kVGwkLm+svMw07BBZFtU6UK+IS41h0ehGLzyzG1syW8Q3H82bFN9WCRIqSR2R1ydE0zyDSKg7Jn8flVnHIF8ys9be+Rt6HLaMK3K2vr2JqZMqIOiNY02kNpa1KM+afMXyy9xOCo4O1jqYoSjZkqA9BCNFJCPGvEOKRECJcCBEhhMi/c14bUjl3aDUOzm2A039onSZXuRR3YWWHlYx2H82hu4fw8vFiw+UNavI/RcmnMtrJPAfoD9hJKW2llDZSSlsD5srfmo0Gh8bw12fw6LrWaXKVsc6YgTUGsr7LeqoWr8qkw5N4f9f73Iq4pXU0RVEyKaMF4hZwVqpfBTNGZwTdFoEQsKFgzPqaWRVtK/Lbm7/xVaOvOPvwLN03dWd54HI1+Z+i5CMZLRCfA1uFEOOFEKOfPbJ6UCHEDCHEBSHEaSHERiFEwevNLeqgv/X19gnY/HGh6Y94nk7o6OXSCx9PH+qXrs/0E9N5d/u7XH1yVetoiqJkQEYLxDdANGAO2Dz3yKpdQA0pZS3gEjA+G23lXa5dodV4/TrWB2ZqnUYzpa1KM+/1eUxrPo2b4TfpsbkHC04tID5RTf6nKHmZcQa3KyulrJFTB5VS7nzu5VGgR061nee0HAuPrsGeqVC8MtTornUiTQgh6Fi5I43LNmbasWn8HPAzO2/sZEqTKdSwz7G/Woqi5KCMnkFsFUK0M1CGQcC2V30ohBgihPATQviFhOTDNZOFgC4/6TutNw6DW8e1TqSp4ubFmd5yOnNbzyUsJoy+W/syy28WTxOeah1NUZSXpDlQLmUjISIAKyAWiAcEINO6k0kI8TdQOpWPJkgpfZO3mQDUA7plpAM8zw+US0tUKPzaBmIj4P3dUMxR60Sai4iLYJb/LNZdWoeDjQPeTbypX7q+1rEUpcDJ6kC5DBUIQxBCDAA+ANpIKaMzsk++LhAADy/ri4R1aRi8s9CMtE7P8XvH8T7iza2IW/Ss2pNR7qOwMc1OF5eiKM8zyEhqIYRjOp8LIUT5zB5UCOGB/s6oLhktDgWCfRXovQIeXYU/B4DqpAWgQZkGrO+ynv7V+7P+8nq8fL3Yf3u/1rEUpdBLrw9ihhBivRDiXSGEqxCipBDCQQjxuhDia+AQUC0Lx52H/i6oXUKIACHEgiy0kT9VagGdf4Rre2HrZ4Xy9tfUWBhb8Fn9z1jRfgW2prZ8uPtDxu4fy6OYgrWcq6LkJ+leYhJCVAf6Ak2BMuhvdz0PbAXWSSlzbWmxfH+J6Xl/e+tnfm03FZqM1DpNnhKfGM+vZ35l0ZlF2JjYML7heDwcPdTkf4qSRfmuDyIrClSBSEqCdQMgcJP+slO1TlonynMuP77MpMOTOPPwDK3Kt2JCowmUtkrtvgdFUdJiqD6Iz5973vOlz77N7MGU5zxbia5cXf10HHf/1TpRnlOlWBWWt1/OmHpjOHrvKF19u/LnpT9JkklaR1OUQiG9Pog+zz1/ebSzRw5nKXxMLKDParC0g1V9IOy21onyHCOdEe+6vsuGLhuobledKUem8N7O97gZflPraIpS4KVXIMQrnqf2WskKm1Lw9lqIi9IXidgIrRPlSRVsK/Bru1/xbuzN+dDzdN/UnWXnlqnJ/xTFgNIrEPIVz1N7rWRVqerQaykEB8K6wZCYoHWiPEkIQfeq3fHx9KFR2UbM9JtJv639uPz4stbRFKVASq9A1H62QBBQK/n5s9c1cyFf4eHcFjpMh8s7YOcErdPkaaWsSjG39VxmtJjB3ai79NrSi18CfiEuMU7raIpSoKRXIMyfWyDIOPn5s9cmuZKwMKn/HjQaDscWwLGFWqfJ04QQeFTywMfTBw9HD+afmk/vLb05HXJa62iKUmCkVyCO5UoK5X/aTQWXDrDtc/BbonWaPK+YeTG+a/4dP7f5mYi4CPpt7cf0E9OJji88A/QVxVAy00mt5AadEfRYAs5vwJZP4MSvWifKF1qUb4GPpw+9XHqxPHA53Td159g99fuNomRHmgPlhBC3gVmv+lxK+crPDKFADZRLT0IsrH0XLm2H9jOg4RCtE+Ubfvf98D7izY3wG3Sv0p3R9UZja6qWUFcKL4MMlAOMAGteXEUuJ1aUU9JjbAa9loNLR9g2Bo78onWifKNe6Xqs67yOgTUGsvHKRrx8vNhzc4/WsRQl30nvDOKklLJuLuZJU6E6g3gmIQ7WD5fDrLQAACAASURBVILzm9W8TVlw7uE5Jh6eyKXHl/Bw9GBcg3HYWdhpHUtRcpWhziBS7YMQQlQQQozJ7MGULDA21fdJVPeCnV/qJ/hTMszV3pU1ndYwwm0Eu2/uxtPXk81XN5Of5iBTFK2kVyDaPHsihCghhBguhDgA7ANKGTKY8hwjE+i+WL+e9d/esH+m1onyFROdCR/U/oA/O/9JRduKfHHwCz7c/SH3o+5rHU1R8rT0CkS8EKK/EGIHcBxwAipJKZ2klJ8ZPp6SwsgYui6Cmr1gz9ew73utE+U7TkWd+N3jd8bWH4vfAz+8fL3448IfavI/RXmF9ApEMDAImApUllJ+CqjhqloxMoauC6D2W7DvW9j7rVpwKJOMdEb0q96PDV02UNO+JlOPTWXQjkHcCL+hdTRFyXPSKxDjATPgF2C8EMLJ8JGUNOmMwPNnqNMP/vke9kxVRSILytuUZ9Ebi5jSZAqXHl+i+6bu/Hb2NxKS1DxYivJMmgVCSjlHStkI8Ex+ywcoK4QYK4SoavB0Sup0RtD5J6jbHw7M1PdLqCKRaUIIulbpiq+nL83KNWO2/2z6bu3LxUcXtY6mKHlCemcQAEgpr0kpv5VS1gTqAUXQLzmqaEWng05zoN4gODRHf4eTKhJZUsKyBLNbzeaHlj9wP+o+fbb04ad/f1KT/ymFXoYKxPOklGellF9IKZ0NEUjJBJ0OOs6CBkPgyDzYPl4ViSwSQtDOsR2+nr50qNyBRacX0XNzTwKCA7SOpiiaSW/J0etCiGvPPZ5/fTW3QippEALaT4eGw+DYfP0kf6pIZFlR86J80+wb5redz9OEp7y77V2+P/69mvxPKZTSO4OoB9R/7tEA+AH9ADr1q1VeIQR4fAeNR8DxRfDXp5Ckbt3MjmblmrHRcyO9XXqz4vwKum3qxuG7h7WOpSi5Kr1O6lApZSjwGOgE7AUaAx2llN1zIZ+SUULop+Jo+jH4LdbPBKuKRLZYmVgxodEElnos1Q+22/UBEw9NJCw2TOtoipIr0rvEZCKE+AAIBJoDXlLKflLKwFxJp2SOENB2MjT/FE4ug00jITFe61T5nnspd9Z1WcfgGoPZdHUTXr5e7L6xW+tYimJwGZnuOwGYA9x8+XMp5YYsHVSIr9HfOpuEfjDeACnl3fT2K5ST9WWFlPoxEvu+g0otoedSsCyudaoCITA0kEmHJ3Hh0QXaVWzH+Ibjsbew1zqWoqQpq5P1pVcglgKv2kBKKQdl9oDJ7dpKKcOTn38EVJdSDk1vP1UgMunflfpLTUXKw9trwb6K1okKhPikeJadW8b8gPmYG5sztsFYOlfujBBqfS0lbzJIgcgNQojxgIOUclh626oCkQU3j8KavvpLTT2XgHOb9PdRMuRa2DUmHZpEQEgATcs2ZWLjiZS1Lqt1LEX5D0OdQYxOa+fsrCgnhPgGeBcIA1pLKUNesd0QYAiAg4OD+40bas6cTHtyE1b1gZAL+rudGgzR91co2ZYkk1hzYQ1zTs5BIPjE/RN6u/RGJzI9xEhRDMZQBWJSWjtLKSense/fQOlUPpogpfR9brvxgLmUMs1jgTqDyJbYCNgwBC5uBfeB0GGGfhpxJUfcibzDlCNTOHz3MHVL1sW7iTeVilTSOpaiAPn7EpMDsFVKWSO9bVWByKakJNg9WT81h2Nz6PW76rzOQVJKNl3dxPQT04lJiGGY2zD6u/bHRKcKsaItQ60ohxCitRBivRDiXPJjnRCiVZZS/q/N53tLPYEL2WlPySCdDt6YDF4L4NYx+L/XIeSS1qkKDCEEns6e+Hr50rJCS348+SN9/+rL+dDzWkdTlCxJbxxER+A3YAvwNtAX/SR9vwkhOmTjuNOEEGeFEKeBdsDH2WhLySy3t6D/FoiLhF/bwpW/tU5UoNhb2DOr1Sxmt5pNcHQwb/31Fj+e/JHYxFitoylKpqTXB7EP+FhKeeql92sBP0kpWxo23ovUJaYc9uQmrH4LggPhzW+h4VDVeZ3DwmLDmOk3E58rPjjaOjKl6RTqlKyjdSylkDHUJabSLxcHACnladSa1PlfUQcYtANcOsD2cfoxE2rkdY4qYlaEr5t+zcK2C4lLjKP/tv58e+xbouKjtI6mKOlKr0Ck9bdY/Q0vCMysoddyaDYa/JfC8q4Q/UjrVAVOk3JN2Oi5kbervc2aC2vo6tuVQ3cOaR1LUdKU3iWmJ8D+1D4CmkkpixkqWGrUJSYDO/WHfv4m27Lw9h9QwkXrRAVSQHAAEw9P5HrYdbo4deHz+p9TxKyI1rGUAsxQ4yDS7GOQUv6T2QNmhyoQueDWcVjzNiTEQo8lUKWt1okKpNjEWBaeWsiSs0soYlaECY0m8EbFN7SOpRRQuT4OQgjRVEqZq+fIqkDkkie3kjuvz0G7b6DRMNV5bSAXHl1g4qGJnH90nrYObfmi4ReUsCyhdSylgDFIJ7UQwkgI8ZYQ4jMhRI3k9zoJIQ4D87KYVcnrilaAQdv1ndc7xsPmjyBBrc9sCK8Vf41VHVfxSd1P2H97P56+nmy8vBGtB7AqCmRsNtcKwHGgIXAX/Spz46SUPrkR8HnqDCKXJSXB3qlw4Aeo2Ew/8trKTutUBVZQWBCTDk/iZPBJGpdpzKQmkyhnXU7rWEoBYKg+iLNALSllkhDCHLgPOCWvMpfrVIHQyOm14DsCbMvo73gqU0vrRAVWkkziz4t/Mst/FhLJx3U/po9LH4x0RlpHU/IxQ42DiJNSJgFIKWOAa1oVB0VDtXrBwK0QH6OfnuPQj5CUqHWqAkkndPR+rTc+nj64l3Jn2vFpDNg+gGtPrmkdTSmE0juDiAauPHsJOCW/FugXDMrVXyXVGYTGokJhy8dwfrP+klPXBfr+CsUgpJRsubaF7098T3R8NENrD2VgjYFq8j8l0wx1ialiWjtLKXN1cQZVIPIAKSFgJWwbC8IIOv4AtXpqnapAC30aynfHv2NH0A6qFqvKlKZTcLVz1TqWko8Y5BKTlPJGchHQATWTH0bPva8UNkJAnX4w9CCUfA02vAfrBsHTx1onK7DsLOyY2XImc1rP4XHMY/r+1ZfZ/rOJSYjROppSwKV3m6utEGItsBsYlPz4WwjxpxDCNjcCKnlU8UowYCu8/iUE+sL8pnAtV8dNFjptHNrg4+WDl7MXv539jR6be+B3X51RK4aTXif1XCAQcJZSdpNSdkPfD3EGNQ5CMTKGFmNg8C4wsYDfu8COCfpR2IpB2Jra4t3Em/9r938kJCUwcMdAph6dSmRcpNbRlAIovT6Iy1LKKpn9zFBUH0QeFhcFO78Cv8VQ0hW6/x+UUtfJDSk6Ppp5AfNYEbiCUlal+KrRV7Qo30LrWEoeZLAV5dI6Zjb2VQoaUyvoNAveXgtRwbCoFRyepx9spxiEpYkln9f/nOUdlmNlbMWHuz9k/IHxPI5R/UFKzkivQBwWQkwU4sWJeIQQXwFHDBdLybeqvgnDj4LzG7BzAiz3hLA7Wqcq0GqXqM3azmsZWnso269vx8vXi+1B29V0HUq2pXeJyRZYDNQFApLfrgOcBAZLKcMMnvA56hJTPiIlnPwdto/X91V0mgM1ummdqsC79PgSEw9N5FzoOVpXaM2Xjb6kpGVJrWMpGjPobK5CCCegevLLQCnl1cweKCeoApEPhV6FDUPgjh/U6g0dZoC5WvvAkBKSElh5fiU//fsTpjpTPq33Kd2qdEOoGXkLLYP1QQghTIEWQMvkRwshhFnmIyqFkp2TflnTVuPhzDr97bBBaiU1QzLWGdPftT8bumzApbgL3ke8eX/n+9yKuKV1NCWfSW8cRHX0t7m2Am4mP1oB55I/U5T0GRlDq3EweCcYmcDSjrBrkppC3MAcbB1Y/OZiJjaeyNnQs3Tz7cbv534nUc2jpWRQen0Qu4FpUspdL73fFpggpWxt4HwvUJeYCoDYSNjxBZxcBqVrQrdf9SOyFYO6H3Wfr49+zf7b+6llXwvvJt5UKZard6krGjLUJaZyLxcHACnl30DpzB5MUTCzhi5zoc9qCL8Li1rCsYXqdlgDK21Vmnmvz+P75t9zK+IWvbb0Yn7AfOIT47WOpuRh6RUIXWr9DclrQxgbJpJSKLzWAYYdgUotYNvnsLI7hN/TOlWBJoSgQ+UO+Hj58EbFN/jl1C/02tKLsw/Pah1NyaPSKxC/A+ufn9VVCOEIrAWWZ/fgQohPhRBSCGGf3baUfMimlH5gXcdZcOMI/NIITixWa00YWHHz4kxvMZ2fXv+J8Lhw+m7ty8wTM3ma8FTraEoek95srlOB7cABIcRDIcRD4B9gl5RySnYOLISoALRD3/GtFFZCQP3BMPQAlKoBf43WX3a6ocZhGlqrCq3w8fShW5VuLAtcRvdN3Tlx/4TWsZQ8JEPjIACEEDYAUsqIHDmwEOuArwFfoJ6U8mF6+6hO6gJOSji3EXZ+CeF3oGYveGMy2JbVOlmBd/zecbyPeHMr4hY9qvZgtPtobExttI6l5BCDdFILIUYLIQaDvjA8Kw5CiMFCiE+yFhWEEJ7AHSnlqQxsO0QI4SeE8AsJCcnqIZX8QAj9aOsRJ/SzxAb6wk/14OBsNUOsgTUo04D1XdYzwHUAGy5vwMvXi39uqenbC7v0bnP1BxpJKeNfet8U8EtryVEhxKvudJoAfAG0k1KGCSGCUGcQSmoeXddPH37xLyjuBB7ToGo7rVMVeGdCzjDx8ESuPLlC+0rtGddgHMXNi2sdS8kGQy05ekpKWfsVn52RUtbM9AGFqIl+AaLo5LfKA3eBBlLK+2ntqwpEIXXlb9g2DkIvQ5U3weM7/QhtxWDiE+P59eyvLDq9CBsTG8Y1GEf7Su3VdB35lKHGQeiEEKVSOdh/3ssoKeUZKWVJKaWjlNIRuA3UTa84KIWYc1sYdhjaTYUbh/V3O/3trR90pxiEiZEJw2oPY22ntZS3Kc/YA2MZuWck96PUP9PCJL0CMQP4SwjRUghhk/xoBWwBZho8naI8Y2wKTUbCSD+o0UPfLzGvHpz+U9+5rRhElWJVWN5+OWPqjeHYvWN4+Xqx9uJakqQa2FgYpHsXkxCiPTAOqAFI4Bz66Te2GT7ei9QlJiXFreOwdQzcCwCHxtB+OpR5ZZeYkgNuhd/C+4g3x+8fp37p+ng39sbB1kHrWEoGGHS677xCFQjlBUlJ8O9y2D0Znj4G94Hw+pdgqTpUDUVKyYbLG5jpN5P4pHhGuI2gX/V+GOvUxAp5Wa4tOSqEOJnZfRTFIHQ6cO8PI/2hwRDwXwpz68Dx/1OjsQ1ECEH3qt3x8fShcdnG/OD/A+9sfYdLjy9pHU0xgPTGQWxNnlrjhbcNlkZRssKiGLT/HoYe1M8Qu/UzWNhSrTthQKWsSjG39VxmtJjB3ai79N7cm58DfiYuUU3hXpCkdwaxBNgphJgghDBJfu8vA2dSlKwpVR36b4aeyyDmCSztAOsGqzWxDUQIgUclD3w8ffCo5MGCUwvovaU3p0NOax1NySEZ6aS2Br4CPNBP0Jdy+4KUcpZB071E9UEoGRYXDYfmwME5oDOCFp9B4xFgrBZDNJT9t/cz5cgUgqOD6Ve9HyPcRmBpYql1LAXD9kHEAVGAGWDz0kNR8iZTS2j9BYw4Dk6vw+4p8HNDuLhd3RZrIC3Kt8DH04deLr1YHric7pu6c+zeMa1jKdmQ3khqD2AWsAmYIqWMfuXGuUCdQShZdnUPbBsLDy+B8xv6aTvsnbVOVWCduH+CyUcmcyP8Bt2rdGd0vdHYmtpqHavQMtRUGweAoVLKc9kJl1NUgVCyJTFev3rdvmkQHw21ekPzT1WhMJCYhBh+OfULy84tw87cji8bfcnrDq9rHatQUuMgFCWjIoP1I7H9lkBiLLh2heaf6Tu5lRx37uE5Jh6eyKXHl/Bw9GBcg3HYWdhpHatQUQVCUTIrMhiOzNOvYhcXCa910k8zXtZN62QFTnxSPL+d+Y2FpxdiaWLJ2Ppj6VS5k5r8L5eoAqEoWRX9CI4tgKMLIDYMqrSDFp9DhfpaJytwrj65ysTDEzkdcprm5ZozsfFESlultiqAkpNUgVCU7IoJ04/CPvIzPH0ElVpCy8/BsZnWyQqUxKREVl9Yzdx/56ITOkbVHUVPl57oRKYndlAySBUIRckpsZHgvwQOzYWoYHBooh9H4fS6ftU7JUfcjrjN5COTOXrvKO6l3JncZDIVbStqHatAUgVCUXJa/FM4uVw/4C78DpRz1/dRVPVQhSKHSCnxueLDDL8ZxCXGMdxtOO9Wf1dN/pfDVIFQFENJiIWAVXBwFjy5CaVq6s8oqnXRTxioZFtIdAjfHPuG3Td3U614Nb5u+jUuxV20jlVgqAKhKIaWGA9n1sGBmRB6Bexd9IXCtRsYqd94s0tKya4bu/jm2DeEx4YzsMZAPqj9AWZGanqU7FIFQlFyS1IiBPrA/pkQHAjFK0Oz0fqBd8amWqfL957EPGGG3ww2Xd1EpSKVmNJkCm4l1a3H2VFoC0R8fDy3b98mJiZGo1RKoSUlJMTo735KjAOdMZjZgKm16qPIATEJMTyJfcKN6BuEmocyrM4wNflfFmW1QOT78+Lbt29jY2ODo6OjGnSjaENKiI2AiPsQHwW6JLAuCZZ2+plklSxLSEyg/L3yHLx2kG6bujGx8USalG2idaxCI9/3sMXExGBnZ6eKg6IdIcDcFuyrgJ2zfkrx8Dv6y08R99XqdtlgbGSMczln6havi4nOhA92fcBXh74iLDZM62iFQr4vEIAqDkreIIT+EpN9FbCrAiYWEHEPHpzT/zcpQeuE+ZIQAlMjU9Z1Wcd7Nd9j89XNePl6sfvGbq2jFXgFokAoSp5jZq0/m7Cvqu+TiLivLxThd/S3zSqZZmZkxsd1P2ZVx1XYW9jzyb5PGL1vNA+fPtQ6WoGlCkQOMDIyws3NjRo1atCzZ0+io1+9bMa+ffs4fPhwyusBAwawbt26NNsPCgqiRo0aWc7XqlUrXFxcqF27NvXr1ycgICDlM0dHRx4+1PYfWEBAAFu3bk13u6CgIFatWpXy2s/Pj48++ijH8/j4+BAYGJjudhn5f4epFdhVhhIuYGarnyAwOBAeXtbPASWT0t4/EyZMmECFChWwtrZ+5Tbx8fH079+fmjVrUq1aNb777ruUz7Zv346LiwvOzs5MmzYt5f3r16/TsGFDnJ2d6d27N3Fx+nWnY2Nj6d27N87OzjRs2JCgoKCUfb777jucnZ1xcXFhx44d6R4jM6rbVWdVx1V8XPdj/rn1D54+nmy6uon8dMNNfqEKRA6wsLAgICCAs2fPYmpqyoIFC1657csFIresXLmSU6dOMXz4cMaMGZPrx09LVgtEvXr1mDt3bo7nyWiByBQTSyheCUq5gk0Z/V1PT27A/bMQdls/ajubOnfuzPHjx9Pc5s8//yQ2NpYzZ87g7+/PwoULCQoKIjExkQ8//JBt27YRGBjI6tWrU/4Mxo4dy6hRo7hy5QrFihVj8eLFACxevJhixYpx5coVRo0axdixYwEIDAxkzZo1nDt3ju3btzN8+HASExPTPEZmmehMeK/me/zZ5U8qF6nMhIMTGPb3MO5G3s1Se0rqNLmLSQjhDbwPhCS/9YWUMv2fEOmYvPkcgXfDs9vMC6qXtWVSZ9cMb9+8eXNOnz7N5s2bmTp1KnFxcdjZ2bFy5UqePn3KggULMDIyYsWKFfz0008A7N+/n1mzZnH//n2mT59Ojx49/tNuQkICffv25eTJk7i6uvL7779z9OhR5s6di4+PDwC7du3il19+YePGja/M17hxY2bMmJHh7xMUFMQ777xDVFQUAPPmzaNJkyYkJSUxYsQI9uzZQ4UKFTAxMWHQoEH06NEDf39/Ro8eTWRkJPb29ixdupQyZcrQqlUrGjZsyN69e3ny5AmLFy+mYcOGTJw4kadPn3Lw4EHGjx9P7969U80ybtw4zp8/j5ubG/3796dOnTrMnDmTLVu24O3tzfXr17l27Ro3b95k9uzZHD16lG3btlGuXDk2b96MiYnJK7M9c/jwYTZt2sQ///zD1KlTWb9+PXv27GHRokXExcXh7OzM8uXLsbR88XbLr776ilu3brF48WJmzZrF2rVriY2NpWvXrkyePJmgoCDat29Ps2bNOHz4MOXKlcP3j+VYyGiIeghRIWBiBVZ2YF40S3c/NWrUKN1thBBERUWRkJDA06dPMTU1xdbWluPHj+Ps7EzlypUB6NOnD76+vlSrVo09e/akFOb+/fvj7e3NsGHD8PX1xdvbG4AePXowYsQIpJT4+vrSp08fzMzMqFSpEs7OzimFK7VjVK9enXHjxrFp0yaMjY1p164dM2fOzNB3rlykMsvaL2PNhTXMOTmHrr5d+cT9E3q79FaT/+UALf8EZ0sp3ZIf2S4OeUFCQgLbtm2jZs2aNGvWjKNHj/Lvv//Sp08fpk+fjqOjI0OHDmXUqFEEBATQvHlzAO7du8fBgwfZsmUL48aNS7XtixcvMnz4cM6fP4+trS2//PILrVu35sKFC4SE6OvskiVLGDRoUJoZt2/fjpeXV4a/U8mSJdm1axcnT57kjz/+SLmks2HDBoKCgggMDGT58uUcOXIE0F/CGDlyJOvWrcPf359BgwYxYcKEF/6Mjh8/zpw5c5g8eTKmpqZMmTKF3r17ExAQ8MriADBt2jSaN29OQEAAo0aN+s/nV69eZc+ePWzatIl+/frRunVrzpw5g4WFBX/99Ve62QCaNGlCly5dmDFjBgEBATg5OdGtWzdOnDjBqVOnqFatWspv0M+MGTOGkJAQlixZwu7du7l8+TLHjx8nICAAf39/9u/fD8Dly5f58MMPOXfuHEWLFmX9X7v+d1ZhWxaSElj52wLcarrqH7Vr4ebmhpubW6q/NGRFjx49sLKyokyZMjg4OPDZZ59RvHhx7ty5Q4UKFVK2K1++PHfu3CE0NJSiRYtibGz8wvvAC/sYGxtTpEgRQkNDX9lWWsfYuHEj586d4/Tp03z55ZeZ+k46oePtam/j4+lDnZJ1+PbYtwzYPoDrYdez/Oek6OX7cRDPy8xv+jnp6dOnuLnpR3o2b96cwYMHc/HiRXr37s29e/eIi4ujUqVKr9zfy8sLnU5H9erVefDgQarbVKhQgaZNmwLQr18/5s6dy2effcY777zDihUrGDhwIEeOHOH3339Pdf++ffsSFxdHZGTkC30Q6YmPj2fEiBEEBARgZGTEpUuXADh48CA9e/ZEp9NRunRpWrduDegL2dmzZ3njjTcASExMfOE39G7dugHg7u7+wjXrnNC+fXtMTEyoWbMmiYmJeHh4AFCzZk2CgoLSzfYqZ8+e5csvv+TJkydERkby5ptvpnz29ddf07BhQxYtWgTAzp072blzJ3Xq1AEgMjKSy5cv4+DgQKVKlVL+nrzw/Y1MwLoUWJWk7/sO9O3bF54+AaT+TihLe7AoliN/RsePH8fIyIi7d+/y+PFjmjdvTtu2bXOk7awqUqQI5ubmDB48mE6dOtGpU6cstVPWuizz285n09VNTD8xnR6bejDMbRj9XftjojPJ4dSFg5YFYoQQ4l3AD/hUSvk4tY2EEEOAIQAODg65GC/jnvVBPG/kyJGMHj2aLl26sG/fvpRT8dSYmf1vrplXdbS9fCvvs9cDBw6kc+fOmJub07Nnz5Tf9F62cuVK3N3dGTNmDCNHjmTDhg0Z+WrMnj2bUqVKcerUKZKSkjA3N09zeyklrq6uKWcUL3v2XY2MjEhIyNnbPp+1rdPpMDExSfkz0ul0JCQkpJvtVQYMGICPjw+1a9dm6dKl7Nu3L+Wz+vXr4+/vz6NHjyhevDhSSsaPH88HH3zwQhtBQUEv/H82MjLi6dOX+h2EYOU63+RLgFI/fiIpAaTEuZID65b/Clb2+v6MLN7avWrVKjw8PDAxMaFkyZI0bdoUPz8/KlSowK1bt1K2u337NuXKlcPOzo4nT56QkJCAsbFxyvsA5cqV49atW5QvX56EhATCwsKws7NLef/ltoBU3zc2Nub48ePs3r2bdevWMW/ePPbs2ZOl7yeEwNPZk6blmvLtsW/58eSP7AzayeQmk6lmVy1LbRZmBrvEJIT4WwhxNpWHJzAfcALcgHvAD69qR0q5SEpZT0pZr0SJEoaKm+PCwsJS/lEsW7Ys5X0bGxsiIiIy3d7NmzdTfrCtWrWKZs30i9iULVuWsmXLMnXqVAYOHJhmG0IIvv76a44ePcqFCxcy/D3KlCmDTqdj+fLlJCbqB301bdqU9evXk5SUxIMHD1J+aLq4uBASEvLCJadz586leYyX/0yOHz/Ou+++m+52mZXRbC8fJyIigjJlyhAfH8/KlStf2NbDw4Nx48bRsWNHIiIiePPNN/ntt9+IjIwE9JdhgoODM5yxb9++BAQEEBBwioDTZwk4c56Af0+ybsViiHkCDy9ByAX93VCJmS+wDg4OKT98o6KiOHr0KK+99hr169fn8uXLXL9+nbi4ONasWUOXLl0QQtC6deuUu7WWLVuGp6cnAF26dEn5u71u3Tpef/11hBB06dKFNWvWEBsby/Xr17l8+TINGjR45TEiIyMJCwujQ4cOzJ49m1OnTmX6e73M3sKeWa1mMbvVbIKjg3nrr7f48eSPxCaqW4wzw2AFQkrZVkpZI5WHr5TygZQyUUqZBPwf0MBQObTi7e1Nz549cXd3x97ePuX9zp07s3HjRtzc3Dhw4ECG23NxceHnn/+/vTOPr+Hc//j7ySKySCy1h9iXkEXEEhq13IqgsbtUFUVb1fYWpfRepffSW6X0p+hii15KS0u1tNXaKSV2jVhrbZGkkoggEd/fH3PO6UmcE4mGc/C8X695nTMzz8x8Z+ac+c7zfZ7n851J3bp1uXTpEkOGDLGs69OnD5UqVaJu3du/IXl6ejJixIgcDdXBwcH4+/vj7+/P8OHDc5R/RqsijwAAIABJREFU4YUXWLBgASEhISQkJODt7Q1At27d8Pf3JzAwkKeeeoqwsDD8/PwoUqQIy5Yt47XXXiMkJITQ0NDb9tpq1aoV8fHxhIaG8tlnn3H69Gk8PT1vKRccHIyrqyshISFMmzbttueam/za1qtXLyZPnkyDBg04fvy4JYzUvHlz6tSpc0v5Hj16MHjwYGJiYoiMjOTJJ58kIiKCoKAgunfv/pecGkoZXWWLV4ay9cGvEigXYzzFhYNw6aQh8yHCqFGj8Pf3JyMjA39/f0utdeXKlbzxxhsADB06lPT0dOrVq0ejRo0YMGAAwcHBuLm5MWPGDKKioqhbty49e/akXj0jZDtp0iSmTp1KjRo1SE5OZuDAgQAMHDiQ5ORkatSowdSpUy3dVuvVq0fPnj0JDAykXbt2zJw5E1dXV7vHuHz5Mh07diQ4OJhHH32UqVOn3vn1ysXfAv7GV52/4onqTzDnwBy6r+zOnot7Cm3/DzoOEetTSpUXkd9N34cBTUSk1+22syXWd+jQoXw9GB9kXnzxRRo0aGD5494r0tPT8fHxITk5mcaNG7N161bKlfvr+YVHjhxJ3759CQ4OLgQrH1CyMiAjGTIugWSDq4eh/eRV0mjTeMAojP/5T7/9xL+3/Zvf0n+jV51e/CPsH3i7exeShc7N/SbW945SKhQQ4CTwXN7FNfZo2LAh3t7evPuu3SjdXaNjx46kpKSQmZnJ2LFjC8U5AAXqhvvQ4u4Ffl5QrKIRespIgsu/GZIeRX2Nhm2PYlpV1opmFZrxZcyXTN8znU8PfcqGMxsYFzGO5hWbO9o0p+W+l/vWNQiNxkTWNaNWcfUPo3HbtYhRo/Asdd/nqSjs//nei3t546c3+DX1V2KqxzCq0Sj8PPwKbf/Oxp3WIPRIEo3mQcG9KPhVNMZVlKhihJ0un4eLv0DycaPrbCFKe9zPhJYJZekTSxkcNJjVJ1YTsyKGNSfXONosp0M7CI3mQUO5GOMmHqkBZQKNMRZZV+HSr3Ah3pD2uH75oXcWHq4evBz2Mos7LqasV1lGbBzBsPXDSMxIvP3GDwnaQWg0DzJuHsYo7bL1jNSo7l6GtEfyMUMH6tJJuHrpoc5ZUadkHT7t8CnDGg5j87nNdPqqE8uPLtfif2gHodE8HCgFRf0MZdlyQVCiqjF//bLhJM4fMJzGlURDSPAhw83FjWfqP8OyJ5ZRs3hN3vjpDZ774TnOpZ9ztGkORTuIQsAs9x0SEkJYWFihqbWOHz/ermhZs2Z5p11866237vi4+ZKxvkfkVlZ94403+PHHHwv9OPm9XnlJad9rkpOTadWqFT4+Prz44ot2y40fP56KFStadJ1Wf/c9eBYn07s8A8ZMJajtU4S0fZING7cY4acLv/DPYc9Tyb+icb5Wb9L2JL7zsmXXrl0EBQVRo0YNXn75Zad+M6/iV4X57ebzryb/Yl/iPrp81YVFhxaR/ZDWsLSDKATMUhv79u3jv//9L2PGjLmlTGHLStzOCf0VB5EfCvt87JHbQfz73/++K9pBd/t63Q2KFi3Kf/7zn3wpn5oFIvfu3Uv79u0BmD17NgAHDv7CD+s2MGLi+9wsVQuKleeJtq3Y8fV8o53i4p/tFnPnzLEp8Z2XLUOGDGH27NkcPXqUo0eP8t133xXiVSh8XJQLf6/zd1Z0WkHDsg15e8fb9PuuHydSTjjatHvOg+Ugvh0N8zsU7vStbXVVe6SlpVGihCGstmHDBiIjI4mJiSEwMBAwhPkaNmxIvXr1LAJvYKishoWFERISQps2bSzL4+PjadmyJdWqVcuR+8D8Jvv777/TokULS8KizZs3M3r0aIuAYJ8+fQCYOnUq9evXp379+rz33nuW/XzyyScEBwcTEhJC3759Lcs3bdpEs2bNqFatmqU2kft8rl27xoABAwgKCqJBgwasX78egNjYWLp27Uq7du2oWbMmo0aNsux3zZo1REREEBYWRo8ePSySFLYwS2+PHDmS0NBQjh8/nqN2U6VKFcaMGUNoaCjh4eHs3r2bqKgoqlevniMnx+TJk2nUqBHBwcGMGzfuluPYul727pOZpKQkIiIiWLVqFYmJiXTr1o1GjRrRqFEjtm7dChhv7s8884zN+1cYeHt78+ijj95WH8se8fHxtG7dGjBUe4sXL07cvl+gWDmaRv+d8sGtjNCUW1FLu8VXSxfRr0tbuJpC965dWLt2LSJi15bff/+dtLQ0mjZtilKKp59+2iJPP336dAIDAwkODqZXr9uOk73nlPcpz6w2s/hv5H85lXaK7l935+P9H5N1M8vRpt07ROS+mRo2bCi5iY+P/3Nm9Wsi89oX7rT6tVuOmRsXFxcJCQmR2rVri6+vr8TFxYmIyPr168XLy0tOnDhhKZucnCwiIhkZGVKvXj1JSkqSixcvir+/v6Wcucy4ceMkIiJCrl27JomJiVKyZEnJzMwUERFvb28REZkyZYpMmDBBRERu3LghaWlpOdaLiMTFxUn9+vUlPT1dLl++LIGBgbJ79245ePCg1KxZUxITE3Mct1+/ftK9e3fJzs6WX375RapXr27zfKZMmSIDBgwQEZFDhw5JpUqV5OrVqzJ//nypWrWqpKSkyNWrV6Vy5cpy+vRpSUxMlMjISElPTxcRkbffflvefPPNPK9tv379ZOnSpTbnAwICZNasWSIi8sorr0hQUJCkpaXJxYsXpUyZMiIi8v3338vgwYPl5s2bkp2dLR06dJCNGzfechzr62XvPpnLnT9/Xho3bixr1qwREZHevXvL5s2bRUTk1KlTUqdOndveP2t69uwpISEht0wLFizI89qYmT9/vgwdOtTu+nHjxklAQIAEBQXJgAED5I8//hARkY8++ki6d+8uWVlZcuLECfHz85Nly5bZvi7ZN0QyLkm9OrXkTNwakXO7Rc7tkWpVKkniyQSRG5k2bdm5c6e0adPGMr9p0ybp0KGDiIiUL19erl27JiIily5dyvMcc/zPHUBSRpK8uuFVqR9bX7p+1VUOJh10qD0FBYiTO3jmPlBy30TfWQrDv4q1muu2bdt4+umnOXjwIACNGzfOIfU9ffp0S0KfM2fOcPToURITE2nRooWlXMmSJS3lO3TogIeHBx4eHpQpU4YLFy7g7+9vWd+oUSOeeeYZsrKy6Ny5s0VO2potW7bQpUsXi45S165d2bx5M0opevToYdGKsj6uPQly6/PZsmULL730EgB16tQhICDAIgfepk0b/PyMgUeBgYGcOnWKlJQU4uPjLbLlmZmZREREFPBq5yQmJgYwJL3T09MpVqwYxYoVw8PDg5SUFLvy2y1atMhzv7buU6lSpcjKyqJNmzbMnDmTxx57DIAff/wxRxgsLS3NUjO63f0D+Oyzz/7SNbgdQ4YMYezYsSilGDt2LCNGjGDevHk888wzHDp0iPDwcAICAmjWrBmurnYSFbm4gmdxQ8ajTB0oVRyupRrtE5fPwYUMo4fUtVSLAu3tRnEHBwfTp08fOnfuXKAcJY6glGcpJj82meiq0UzcPpE+q/rQr14/hoQMoajbndXg7gceLAfhBERERJCUlGRJ4mN+KIMRovnxxx/Ztm0bXl5etGzZkmvXruW5v9wS0blj/y1atGDTpk2sWrWK/v37M3z4cJtKqAXFngS59fnkd3uz3SLC448/zuLFi/+yfbmP4+LikuOY1hLftuS38yKv++Tm5kbDhg35/vvvLQ7i5s2bbN++3Wao53b3D+Dvf/87hw8fvmV5Yd3LsmXLWr4PHjzYkm/Bzc0th+hhs2bNqFWrVp77qlixImfOnsW/UiVuuHqSmn6VUrWawvU0Q/LjaorRbfbiISjqR8VHinP27FnL9tbS36tWrWLTpk18/fXXTJw4kQMHDtiVq3cWWlduTXi5cKbGTWXewXmsPb2W8RHjCS9X4EHK9wUPVhuEE5CQkEB2djalSpW6ZV1qaiolSpTAy8uLhIQEtm/fDhipIjdt2sSvvxoZsP744498H+/UqVOULVuWwYMHM2jQIHbv3g2Au7s7WVlGrDQyMpIVK1aQkZHBlStXWL58OZGRkbRu3ZqlS5eSnJxc4OOa92uWvz5y5AinT5+mdu3adss3bdqUrVu3cuzYMcCQmzbXOMaMGWMzVepflfjOr/y29fWyd5/AkEyfN28eCQkJTJo0CYC2bdta0scCBUrIBEYNwtyAbD0VhnMAox3AzPLly6lfvz6A5fcARrpaNzc3S1uZPWxKfBfxgmLloHQd8K0IRXwMaY8riZQvchlfT3e2r1mOZFziE5Nc+M2bNzlz5gytWrVi0qRJpKam5tke5Uz4FvFlfLPxzGk7h+yb2Qz4fgATtk8gPfP+sL8gOLe7vk+wzignIixYsMBmVb1du3Z8+OGH1K1bl9q1a1tyCJcuXZqPP/6Yrl27cvPmTUuaz/ywYcMGJk+ejLu7Oz4+PpaMcs8++yzBwcGEhYWxaNEi+vfvT+PGhqr6oEGDLCGXf/7znzz22GO4urrSoEEDYmNj833eL7zwAkOGDCEoKAg3NzdiY2NzvDHnpnTp0sTGxtK7d2+uXzd0+SdMmECtWrU4cOCAJVxkTa9evRg8eDDTp0+/o663bdu25dChQ5ZQlo+PDwsXLqRMmTI5yllfr3nz5tm8T2ZcXV1ZvHgxMTExFCtWjOnTpzN06FCCg4O5ceMGLVq0yNFIfjepUqUKaWlpZGZmsmLFCtasWUNgYCCDBg3i+eefJzw8nFGjRrF3716UUlSpUoWPPvoIgIsXLxIVFYWLiwsVK1bkf//7n2W/o0aN4tNPP7VIhw8aNIjx48czcOBA+vbtS40aNShZsiRLliyxbcuq71nz3WoCq1di1pSJ9B86nKvXrhPdqjnRjWtzI+0iT/XpQ2paGiLCyy+/TPHixe/JNSssmpRvwhcxXzBz70wWHlrIxrMbGdt0LC388w5f3k9osT6NUxAVFcX333/vaDM0dwu5CdfT4XoqXE0Fc08gt6JGvosi3kbNw7WIzbYLZ/+f70/cz7ifxnEs5Rgdq3VkVKNRlChaOGliC4P7Te5bo8mBdg4POMrFkCEv6gu+/oY21PU0yEw32i0yjDAnLm45HYa7p7GtkxNcOpjPO37O7AOzmb1/Nj/99hNjmowhKiDqlnTB9xPOf+U1Gs2DhVJgbrcoVcOQ/ihdB/z8wcPXcB5pvxnpVX/fD4lHDCdy6BtId14hPXdXd14IfYHPnviM8t7lGblxJP9Y/w8uZuQ/5ayzoWsQGo3GsShl1BTcPcHcSS47CzKv/DldvwwrjUGMlKwGlZpCpcZQuSk8UhtcnOddt1aJWixsv5BFhxbx/p736byiMyPCR9C1Ztf7rjah2yA0Go3Tcyg+nro+aXB6O5zZAWd+NrLoAXj4QaVGfzqNig3Bwzk0s06nnWbcT+OIuxBHk3JNGNdsHJWKVbrndug2CI1G8+CilFFbqGzqUSYCf5wwHIXZaRybYCrrCuXq/+kwKjWB4vf+oQxQ2bcyc6Pm8sXRL3g37l26ftWVlxq8RJ+6fXB1sTMo0YnQNQiNRuP05Ot/fvUSnI0zOYyf4dwuyMow1vlWNDkLk9MoF2SMCr+HnL9yngnbJ7Dx7EaCHwlmfLPx1CxR854cW6ccdSC2JKA//PBDy5gERxAbG8tvv/1mmR80aFAOOYjCICUlhVmzZt223MmTJy2Ds5yBhIQEIiIi8PDwyFMJde3atYSFhREaGsqjjz5qGeA3depUi8hcmzZtOHXqlGUbs/R7aGhojnEdkZGRluUVKlS4RVpi586duLm5WcZ67N27l4iICOrVq0dwcPBdl+N4IPAsATUfhzZjof83MPoMPLsBot8xahFndsJ3r8HsVvB2ZYjtCGv/A0fWGM7lLlPOuxzvt36fSZGTOHP5DD2/6ckHez8gK9uJxf/uRMDJUdNtxfocRG6ht3uBWXzOHo899pjs3Lnzrtrw66+/Sr169Qqt3L3iwoULsmPHDnn99ddl8uTJdsvVrFnT8vuaOXOm9OvXT0RE1q1bJ1euXBERkVmzZknPnj0t2+Tnt9C1a9ccQnw3btyQVq1aSXR0tEWI8PDhw3LkyBERETl37pyUK1futoJ2DzKF9j9POSNyYJnI6lEiH7YQGV9CZJyvMc1oLLLiBZEt/yeSsFok8ahFhLCwSb6aLKM2jpL6sfWl84rOciDxQL62O3/+vPTu3VuqVq0qYWFh0rRpU/nyyy9vux25xPqAKsBBuc0z94Fqg5i0YxIJfyQU6j7rlKzDa41fK/B248ePx8fHh1dffZWWLVvSpEkT1q9fT0pKCnPnziUyMpLs7GxGjx7Nhg0buH79OkOHDuW5554jPT2dTp06cenSJbKyspgwYQKdOnXi5MmTREVF0aRJE3bt2sXq1asJCAi45djLli0jLi6OPn364OnpybZt24iOjmbKlCmEh4fj4+PDkCFDWL16NeXLl+ett95i1KhRnD59mvfee4+YmBi7tlkzevRojh8/TmhoKI8//jjjxo2zabc1J06coFu3bnz88ceULFmSoUOHkpiYiJeXF7Nnz6ZOnTr0798fX19f4uLiOH/+PO+88w7du3cv8D2wR5kyZShTpgyrVq3Ks5xSirS0NMCQ36hQoQIArVq1spRp2rQpCxcuzPex09LSWLduHfPnz7cse//99+nWrRs7d+60LLPWRKpQoQJlypQhMTGR4sWLM3r0aFauXImbmxtt27bNVz4IjQk/f2Oq382Yz7xihKLO/Gy0Yxz+FvZY3U8XNyhRBUrVNHJ8l6ph+l4TvEvfVpDQHiWLlmRSi0lEV43mP9v/Q5/Vfehbty9DGwzF083T5jYiQufOnenXrx+ffvopYEjtrFy58o5syA8PlINwZm7cuMGOHTtYvXo1b775Jj/++CNz587Fz8+PnTt3cv36dZo3b07btm2pVKkSy5cvx9fXl6SkJJo2bWoJVxw9epQFCxbcIv9gTffu3ZkxY4bFIeTmypUrtG7dmsmTJ9OlSxf+9a9/8cMPPxAfH0+/fv2IiYmxa5u1Mu3bb7/NwYMHLdpDN27csGs3wOHDh+nVqxexsbGWvBcffvghNWvW5Oeff+aFF15g3bp1gKEftGXLFhISEoiJibHpICIjI23qNE2ZMqVQkgrNmTOH9u3b4+npia+vbw5NJjNz584lOjraMn/t2jXCw8Nxc3Nj9OjRt4SSVqxYQZs2bfD19QUMbajly5ezfv36HA7Cmh07dpCZmUn16tVJTk5m+fLlJCQkoJQiJSXlL5/nQ00Rb6jawpjMZPwBycch+SgkHTU+k4/D8XWQff3Pch5+UKq64SysHUjJ6sY4j3zQslJLGpZtyLRd01gQv4B1Z9YxPmI8jcsbsjjHj8O778LChXD58jpcXYvQoMHzHD8O1atDQEAAL730EteuXWPIkCHExcXh5ubG1KlTadWqFSdPnjTneamrlNoNvCgi+U55+UA5iDt5079XdO3aFYCGDRta0jSuWbOG/fv3W+LOqampHD16FH9/f15//XU2bdqEi4sL586ds0huBwQE5Okc8kORIkVo164dYMhke3h44O7uTlBQ0G1ts3YQuRERu3YnJibSqVMnvvzySwIDA0lPT+enn36iR48elu3N+kxgX27cms2bN/+l63A7pk2bxurVq2nSpAmTJ09m+PDhzJkzx7J+4cKFxMXFsXHjRsuyU6dOUbFiRU6cOEHr1q0JCgqievXqlvWLFy9m0KBBlvlXXnmFSZMm4WKnH//vv/9O3759WbBgAS4uLvj5+VG0aFEGDhxIx44dLcqsmkLEq6QxVWqUc/nNbEg9A0nHjPzdZgdycgvsz9VG5FfJVNuoYXIgpk9f/1vGbBQrUow3It4gumo0434ax8A1A+leqztBfwynb89iZGWBoSP5C9nZYcyZAwsWwLJlYH43mTlzJkopDhw4QEJCAm3btuXIkSMWXTdPT89DQG9gMZDvxmqHOQil1EvAUCAbWCUio26zyX2NWcTOWvJZRHj//feJiorKUTY2NpbExER27dqFu7s7VapUschN51duOy/c3d0tA3asZbLNEtl52ZYXixYtsmu3n58flStXZsuWLQQGBnLz5k2KFy9uV/nUnty4NXezBpGYmMi+ffto0qQJYEhym50qGDkgJk6cyMaNG3PYapayrlatGi1btmTPnj0WB5GUlMSOHTtyqNbGxcVZsqklJSWxevVq3Nzc6Ny5M2lpaXTo0IGJEydaXgrc3NzYsWMHa9euZdmyZcyYMcNS69LcZVxcjXBTiSpQM9fvK/OKVa3DyoHsWwKZVr9Rt6JGDeMRU6jKyoE0KteIL2K+YNbeWXzyyycsSdmEa62xZOxtmeNQZocREzOUGjW24ONTBH9/f5u5WQICAsw5wgOBpUDeeu65cIiDUEq1AjoBISJyXSlV5nbbPIhERUXxwQcf0Lp1a9zd3Tly5AgVK1YkNTWVMmXK4O7uzvr163P0ksnN008/zYsvvmhRajVTGDLZtmyzdlC5j5GX3UWKFGH58uVERUXh4+PDk08+SdWqVVm6dCk9evRARNi/fz8hISH5tvFu1iBKlChBamoqR44coVatWvzwww+WbpZ79uzhueee47vvvsuhCnvp0iW8vLzw8PAgKSmJrVu35ki3umzZMjp27Jgjb4RZ4h2gf//+dOzYkc6dO5OZmUmXLl14+umnc4TX0tPTycjIoH379jRv3pxq1ardtWugKQBFvKF8sDFZIwLpFwyHkXT0z8/zBw3pEMn+s6x3aTxL1WBEqRoUOfYEsb4/E/DKS6Rub8dvi8aQfbke8IWluFIzadYsibVrw29JQmVm2rRp5nwg8UBTIO8ENLlwVA1iCPC2iFwHEJH7V6wELJLIZoYPH56v7QYNGsTJkycJCwtDRChdujQrVqygT58+PPHEEwQFBREeHk6dOnXs7mP//v2WxlNr+vfvz/PPP29ppC4o9myzplSpUjRv3pz69esTHR3Na6+9lqfd3t7efPPNNzz++OP4+PiwaNEihgwZwoQJE8jKyqJXr14FchB3yvnz5wkPDyctLQ0XFxfee+894uPj8fX1pX379syZM4cKFSowe/ZsunXrhouLCyVKlGDevHkAjBw5kvT0dEt4rHLlyqxcuZJDhw7x3HPP4eLiws2bNxk9enSO/ApLlixh9Oj85Tj//PPP2bRpE8nJyRYJ9tjYWMqWLUunTp24du0aIsLUqVML9+JoChelDM2pYuWgyqM5193IhEsnTW0cVg7k8Le85JrE81dg7iVfPmryLf4Nv4P//YNtm64BHwBDyMqCzz/PoFSpP3OztG7dOkdultTUVOtnU1+gQKPzHDJQTim1F/gKaIfh0V4VEZstdEqpZ4FnASpXrtww99v0wzxQLi0tjYEDB7J06VJHm6LR3FUetv95Sa9L1Cx5nNqljlKuehyHI7Zx7ON3iD9WHRgG/AyUBrxZsuR5OnXqZLOR+ujRo3Tr1o0DBw5cBd4HhoqIj1KqCvCNiOQ5QOmuOQil1I9AORur/glMBNYDLwONgM+AanIbY/RIao3m4eRh+5/7+kJ+IsS+vpCaevtyTqfFJCJ2WwmVUkOAL00OYYdS6ibwCOC8Wr4ajUZzj3jqKZgzx9x7yTbu7mD0YL17OEpqYwXQCkApVQsoAiTd6c4cESbTaDT3hofx/z1ihOEA8sLdHYYNu7t2OMpBzAOqKaUOAkuAfrcLL9mjaNGiJCcnP5Q/Io3mQUdESE5OztHz62GgenVjnIOX162Owt3dWL5smVHubuKQXkwikgk8VRj78vf35+zZsyQm6uiURvMgUrRoUbvdOB9koqNh/36YNg3+9z9ITwcfHyOsNGzY3XcO8ADIfWs0Go0mb7Tct0aj0WgKFe0gNBqNRmMT7SA0Go1GY5P7qg1CKZUI2BcmyptH+Atdae8i2q6Coe0qGNquguGsdsFfsy1AREoXdKP7ykH8FZRScXfSSHO30XYVDG1XwdB2FQxntQscY5sOMWk0Go3GJtpBaDQajcYmD5OD+NjRBthB21UwtF0FQ9tVMJzVLnCAbQ9NG4RGo9FoCsbDVIPQaDQaTQHQDkKj0Wg0NnkoHIRSqp1S6rBS6phSKn85H+8ySql5SqmLJkVbp0EpVUkptV4pFa+U+kUp9Q9H2wSglCqqlNqhlNpnsutNR9tkjVLKVSm1Ryn1jaNtMaOUOqmUOqCU2quUchoRM6VUcaXUMqVUglLqkFIqwglsqm26TuYpTSn1iqPtAlBKDTP95g8qpRYrpe6ZtO0D3wahlHIFjgCPA2eBnUBvEYl3sF0tgHTgk9ul/buXKKXKA+VFZLdSqhiwC+jsBNdLAd4ikq6Ucge2AP8Qke2OtMuMUmo4EA74ikhHR9sDhoMAwkXEqQZ+KaUWAJtFZI5SqgjgJSIpjrbLjOmZcQ5oIiJ3OjC3sGypiPFbDxSRq0qpz4HVIhJ7L47/MNQgGgPHROSESWZ8CdDJwTYhIpuAPxxtR25E5HcR2W36fhk4BFR0rFUgBummWXfT5BRvN0opf6ADMMfRtjg7Sik/oAUwFwzpf2dyDibaAMcd7RyscAM8lVJugBfw27068MPgICoCZ6zmz+IED7z7AVNi8wYYGdIdjimMsxe4CPwgIk5hF/AeMAq46WhDciHAGqXULqXUs442xkRVjNTC800huTlKKW9HG5WLXsBiRxsBICLngCnAaeB3IFVE1tyr4z8MDkJzByilfIAvgFdEJM3R9gCISLaIhAL+QGOllMNDc0qpjsBFEdnlaFts8KiIhAHRwFBTWNPRuAFhwAci0gC4AjhFuyCAKeQVAyx1tC0ASqkSGBGPqkAFwFspVSjJ1vLDw+AgzgGVrOb9Tcs0djDF+L8AFonIl462JzemkMR6oJ2jbQGaAzGmeP8SoLVSaqFjTTIwvX0iIheB5RjhVkdzFjhrVftbhuEwnIXlewk6AAAFdElEQVRoYLeIXHC0ISb+BvwqIokikgV8CTS7Vwd/GBzETqCmUqqq6e2gF7DSwTY5LabG4LnAIRGZ6mh7zCilSiulipu+e2J0OkhwrFUgImNExF9EqmD8ttaJyD17w7OHUsrb1MkAUwinLeDwHnMich44o5SqbVrUBnBoB4hc9MZJwksmTgNNlVJepv9mG4x2wXuCQ3JS30tE5IZS6kXge8AVmCcivzjYLJRSi4GWwCNKqbPAOBGZ61irAOONuC9wwBTvB3hdRFY70CaA8sACUw8TF+BzEXGaLqVOSFlgufFMwQ34VES+c6xJFl4CFple2E4AAxxsD2BxpI8DzznaFjMi8rNSahmwG7gB7OEeSm488N1cNRqNRnNnPAwhJo1Go9HcAdpBaDQajcYm2kFoNBqNxibaQWg0Go3GJtpBaDQajcYm2kFonAqTmuyvSqmSpvkSpvkqucqVU0otUUodN0lJrFZK1TKtq6eUWmdS8D2qlBpr6kNu3razUmq/SUn0gFKqs9W6WNPx9pqUY9tYrdtg2ud+kxLpDPPYDNP6dNNnFaWUKKVeslo3QynV32reTSmVqJR62zT/Tysl0Wyr7y8rpcYrpc7lUhs1jwlpoJQqUPdo03WrWZBtNA8pIqInPTnVhKFr9LHp+0fAmFzrFbANeN5qWQgQCXgCx4G2puVewLfAUKtyx4Cqpvmqpvlg03ws0N30vRVw1OoYGzDUUQGKAO8CG63Wp5s+qwAXTPstYlo2A+hvVTYa2GqyVeU6v/Rc8+OBV+1cq6VASAGv72PAbEffZz05/6RrEBpnZBrG6NFXgEcxxMqsaQVkiciH5gUisk9ENgNPAlvFJGgmIhnAi/yp9/Mq8JaI/Gpa/yvwX2CkDTu2YUfYUQxl4FFAZaVUiI0iicBaoJ+dc+wN/B/GSNk7yodgGikdLCL7TPPjlVILlFKblVKnlFJdlVLvmGpJ35kkVAA2A38zqYNqNHbRDkLjdIihOTMSw1G8Ypq3pj5Gngpb1Mu9TkSOAz5KKV9b64E40/LctANW5GFnNrAPqGOnyCTgVdPobwvKSPjyN+BrDFmH3vaOYcUwq/DSetOycG6Vz6gOtMYQnFsIrBeRIOAqhiQ5InITo3Zjy7FpNBa0g9A4K9EY8saOUGydrJQ6AnyK8ZDPC2VvhYicwJBKfzLXqo4YD+6rGKKInXM7ERtME5FQ09TKtKw8Rk3Fmm9NDvUAhrSMWV7jAEboy8xFDHVQjcYu2kFonA6lVCiGJk5TjDfnSlZvz88DvwAN7Wwen3udUqoaRlw/zdZ607y1PtdIEakFvAbMy8NOVyCIvMXT3jLtx9qR9MYI8ZzEqM2UwnjrLyhXgdzpJ6+DpZaQJSJmLZ2b5NReK2raXqOxi3YQGqfC1NvoA4zQ0mlgMvC21dvzh8A6wENZJcFRSgUrpSKBRcCjSqm/mZZ7AtOBd0xFpwBjzL2iTJ+vYzQ452YG4KKUirJhpztG28UZEdlv73xEJAHDKT1h2s4XozG9sohUEUMFdij5CzPl5hBQ4w62A6iFE6i7apwb7SA0zsZg4LSI/GCanwXUVUo9Zi5geivugvEWflwp9QvGw/q8KWzTCfiXUuowRmhlJ8bDHhHZi/FG/7VSKgGjHWCUaXkOTMeZgNEYbWaRUmo/xsPVm/ylr52IkYcEk93rROS61fqvgCeUUh557MO6DWKvUqqKyfn4mRqr841SqixwVQzpbY3GLlrNVaO5j1FKDQMui0i+82GbtkkT55CX1zgxugah0dzffICp3aEApAAL7oItmgcMXYPQaDQajU10DUKj0Wg0NtEOQqPRaDQ20Q5Co9FoNDbRDkKj0Wg0NtEOQqPRaDQ2+X9ON3ob7BKM7wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Goal reached! episodic-reward= -63.331818\n",
            "Steps taken: 18\n",
            "Time taken:  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-488938b0b65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#init population generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitialPopulationCreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitialPopulationRender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExportPopulationToCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
          ]
        }
      ],
      "source": [
        "RLOpt = RLBaseSolutionBuilder(Brachistochrone_Env,(8.0, -6.0)) #provide target position for initialization\n",
        "SELECTED_MODEL = \"pipeline_test\"\n",
        "change_selected_model()\n",
        "\n",
        "RLOpt.LoadAgentModel(SELECTED_MODEL) \n",
        "#IF YOU WANT YOU CAN TRAIN NEW AGENT FROM SCRATCH -> RLOpt.TrainNewAgent()\n",
        "RLOpt.TrainNewAgent(model_name = SELECTED_MODEL)\n",
        "RLOpt.ValidateAgent()#plot the trace corrinsponding to current loaded agent   !!!read me: LoadAgentModel and TrainNewAgent change current loaded model!!!\n",
        "env = RLOpt.GetEnv()\n",
        "solution_vector = RLOpt.GetBaseSolution() #get base solution for next pipeline step\n",
        "\n",
        "#init population generation\n",
        "opt.InitialPopulationCreator()\n",
        "opt.InitialPopulationRender()\n",
        "opt.ExportPopulationToCSV()\n",
        "\n",
        "opt = OptimizerMiddlewareManager(env,solution_vector,10) #0\n",
        "opt.base_solution_cast() #1\n",
        "opt.CreatePopInTranslatedDomain(0.01) #2\n",
        "opt.TranslatedPopulationRender()\n",
        "opt.ImportPopulationFromCSV()\n",
        "opt.GetInitPopData() #3\n",
        "\n",
        "print(\"opt.cast_pop\")\n",
        "print(opt.cast_pop)\n",
        "print(\"Population Size\")\n",
        "print(opt.cast_pop.shape[0])\n",
        "print(\"Number of Points\")\n",
        "print(opt.cast_pop.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Multi Objective Evolutionary Algorithm (MOEA)"
      ],
      "metadata": {
        "id": "lvlLH_ZWRtDB"
      },
      "id": "lvlLH_ZWRtDB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![GA-Diagram.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "s5PvG2jChX9x"
      },
      "id": "s5PvG2jChX9x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "qFcJYcGEtWQB"
      },
      "id": "qFcJYcGEtWQB"
    },
    {
      "cell_type": "code",
      "source": [
        "ga_selection_method = [\"Tournament\", \"NSGA2\"]\n",
        "ga_objectives = [\"Time\", \"Distance\"]\n",
        "ga_n_dimensions = 2\n",
        "ga_n_individuals = 19\n",
        "ga_n_generations = 10000\n",
        "ga_n_points = 15\n",
        "\n",
        "# Percentage\n",
        "ga_ps = 0.3 # Selection\n",
        "ga_pc = 0.5 # Crossover\n",
        "ga_pm = 0.01 # Mutation\n",
        "ga_elite = 0.1 # Selected group that is superior to the rest of a individuals\n",
        "\n",
        "ga_p_variable = True # Varied the probability\n",
        "\n",
        "# Boundaries \n",
        "ga_xl = 0 # left boundary\n",
        "ga_xr = 1 # rigth boundary\n",
        "ga_yu = 1 # up boundary\n",
        "ga_yl = -1 # low boundary\n",
        "ga_limits = [ga_xl, ga_yl]\n",
        "ga_weights = [0.4, 0.6] # Time, Distance\n",
        "ga_height = 1\n",
        "ga_width = 1\n",
        "\n",
        "ga_seed = 1\n",
        "\n",
        "ga_show_info = True # See Important Info\n",
        "ga_show_debug = False # See Specific info to help the visualization for develop\n",
        "ga_show_plot = False # See Description Prints\n",
        "ga_max_frames = 20\n",
        "ga_parents = []\n",
        "ga_new_individuals = []\n",
        "\n",
        "ga_base_path = \"/content/gdrive/My Drive/Brachistochrone/MOEA\"\n",
        "ga_counter = 0\n",
        "ga_misc_runs_dir = \"\"\n",
        "ga_evolution_dir = \"\"\n",
        "ga_objectives_dir = \"\"\n",
        "\n",
        "date_string = date.today()\n",
        "base_name = f'Env_({date_string})_ind={ga_n_individuals}_gen={ga_n_generations}_pts={ga_n_points}'\n",
        "\n",
        "np.seterr(divide='ignore', invalid='ignore')"
      ],
      "metadata": {
        "id": "VM3-bcaAvSIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422437c3-0980-4930-c0a2-ae9d3be76e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'ignore', 'invalid': 'ignore', 'over': 'warn', 'under': 'ignore'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "id": "VM3-bcaAvSIy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Functions"
      ],
      "metadata": {
        "id": "J7c4bPcZE745"
      },
      "id": "J7c4bPcZE745"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the start config\n",
        "def initConfig(folder=ga_misc_runs_dir, file='config.json', set_global=False, show_debug=False):\n",
        "  file = os.path.join(folder, file)\n",
        "\n",
        "  if Path(file).is_file():\n",
        "    with open(file, \"r\") as f:\n",
        "      myJSON = json.loads(f.read()) # Reading from file\n",
        "      f.close()\n",
        "  else:\n",
        "    globals__ = globals()\n",
        "    config = {}\n",
        "\n",
        "    # Inside our Genetic algorithm, we declare all global values as ga_*\n",
        "    # Easier for search and get all the config values\n",
        "    for key, value in sorted(globals__.items()):\n",
        "      if key.startswith('ga_'):\n",
        "        config[key] = value\n",
        "\n",
        "    myJSON = json.dumps(config, indent = 4) \n",
        "\n",
        "    with open(file, \"w\") as f:\n",
        "        f.write(myJSON)\n",
        "        f.close()\n",
        "\n",
        "  if ga_show_debug:\n",
        "    print(\"\\n----------------------------------------------------------------\")\n",
        "    print(f'Configuration: \\n{file}')\n",
        "    print(myJSON)\n",
        "    print(\"Write successful\")\n",
        "    print(\"----------------------------------------------------------------\\n\")\n",
        "\n",
        "  if set_global:\n",
        "    # set_global = False as default, save the new configuration but don't update the global values\n",
        "    # set_global = True to use the new config from file \n",
        "    globals().update(myJSON)\n",
        "\n",
        "\n",
        "# Create environment Folders\n",
        "def makeFolders():\n",
        "  global date_string, base_name, ga_evolution_dir, ga_objective_dir, ga_misc_runs_dir\n",
        "\n",
        "  date_string = date.today()\n",
        "  base_name = f'Env_({date_string})_ind={ga_n_individuals}_gen={ga_n_generations}_pts={ga_n_points}'\n",
        "  ga_evolution_dir = os.path.join(ga_base_path, \"evolution/\" + base_name)\n",
        "  ga_objective_dir = os.path.join(ga_base_path, \"objectives/\" + base_name)\n",
        "  ga_misc_runs_dir = os.path.join(ga_base_path, \"misc_runs/\" + base_name)\n",
        "\n",
        "  Path(ga_evolution_dir).mkdir(parents=True, exist_ok=True)\n",
        "  Path(ga_objective_dir).mkdir(parents=True, exist_ok=True)\n",
        "  Path(ga_misc_runs_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Normalize an array between given min and max values \n",
        "def normalize(data, min, max):\n",
        "  normal = []\n",
        "  old_min = np.min(data)\n",
        "  old_max = np.max(data)\n",
        "  old_range = old_max - old_min\n",
        "  \n",
        "  new_min = min\n",
        "  new_max = max\n",
        "  new_range = new_max - new_min\n",
        "\n",
        "  if old_range == 0:            \n",
        "      if old_min < new_min:      \n",
        "          new_value = new_min\n",
        "      elif old_min > new_max:    \n",
        "          new_value = new_max\n",
        "      else:                    \n",
        "          new_value = old_min\n",
        "      normal = [new_value for value in data]\n",
        "  else:\n",
        "      scale = new_range / old_range\n",
        "      normal = [(value - old_min) * scale + new_min for value in data]\n",
        "\n",
        "  return normal\n",
        "\n",
        "\n",
        "# Write data into a CSV\n",
        "def exportCSV(data, folder=ga_misc_runs_dir, file='data.csv'):\n",
        "  file = os.path.join(folder, file)\n",
        "\n",
        "  if not Path(file).is_file():\n",
        "    with open(file, 'w', encoding='UTF8', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(data) # Write multiple rows\n",
        "      f.close()\n",
        "\n",
        "\n",
        "# Read data into CSV and return values from file\n",
        "def importCSV(folder=ga_misc_runs_dir, file='data.csv'):\n",
        "  file = os.path.join(folder, file)\n",
        "  list_points = []\n",
        "\n",
        "  if Path(file).is_file():\n",
        "    with open(file, 'r') as f:\n",
        "      csv_reader = csv.reader(f)\n",
        "      for line in csv_reader:\n",
        "        list_points.append(list(line))\n",
        "      f.close()\n",
        "  \n",
        "  return list_points\n",
        "\n",
        "\n",
        "# Create GIF from folder\n",
        "def exportGIF(fp_in, fp_out):\n",
        "  file_list = os.listdir(fp_in)\n",
        "  imgs = (Image.open(os.path.join(fp_in, filename)) for filename in file_list)\n",
        "  img = next(imgs)  # extract first image from iterator\n",
        "  img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
        "          save_all=True, duration=400, loop=0)\n",
        "  img = Image.open(fp_out)\n",
        "\n",
        "\n",
        "# Display GIF\n",
        "def importGIF(folder=ga_evolution_dir, file='gif.gif'):\n",
        "  file = os.path.join(folder, file)\n",
        "\n",
        "  if Path(file).is_file():\n",
        "    with open(file, 'rb') as f:\n",
        "      b64 = base64.b64encode(f.read()).decode('ascii')\n",
        "      f.close()\n",
        "    return display(HTML((f'<img src=\"data:image/gif;base64,{b64}\" />')))\n",
        "  else:\n",
        "    return print(\"File doesn't exist\")\n",
        "\n",
        "# Write data into a TXT\n",
        "def exportTXT(data, folder=ga_misc_runs_dir, file='logs.txt'):\n",
        "  file = os.path.join(folder, file)\n",
        "\n",
        "  with open(file, \"w\") as f:\n",
        "    for row in data:\n",
        "      f.write(row + \"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "CWPwgzl6E_aP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CWPwgzl6E_aP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLp9F2gTVs6P"
      },
      "source": [
        "## Genetic Algorithm Components\n",
        "\n"
      ],
      "id": "PLp9F2gTVs6P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZATLhqOBV4OM"
      },
      "source": [
        "### Initialization"
      ],
      "id": "ZATLhqOBV4OM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Individual"
      ],
      "metadata": {
        "id": "OunaZmudTRs4"
      },
      "id": "OunaZmudTRs4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBQYp6_zhsjA"
      },
      "outputs": [],
      "source": [
        "class Individual():\n",
        "  def __init__(self, \n",
        "               n_points=ga_n_points, \n",
        "               height=ga_height,\n",
        "               width=ga_width,\n",
        "               x=[],\n",
        "               y=[], \n",
        "               random=True):\n",
        "\n",
        "    self.n_points = n_points\n",
        "    self.n_segments = n_points-1\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "    if random:\n",
        "      self.generateIndividual()\n",
        "\n",
        "\n",
        "  # Generate Individual Randomly\n",
        "  def generateIndividual(self):\n",
        "    self.y = [self.height]\n",
        "    self.x = [0]\n",
        "    self.delta_x = self.width/self.n_segments\n",
        "\n",
        "    for i in range(self.n_segments-1):\n",
        "        self.x.append((i+1)*self.delta_x)\n",
        "        frac = 1\n",
        "        self.y.append(-self.height/frac + random.random()*(self.height - (-self.height/frac)))\n",
        "\n",
        "    self.x.append(self.width)\n",
        "    self.y.append(0)\n"
      ],
      "id": "dBQYp6_zhsjA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffE6-Ww1V9cl"
      },
      "source": [
        "#### Population"
      ],
      "id": "ffE6-Ww1V9cl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL1eHy7ANksX"
      },
      "outputs": [],
      "source": [
        "class Population():\n",
        "  def __init__(self, \n",
        "              individual=Individual, \n",
        "              n_individuals=ga_n_individuals,\n",
        "              objectives=ga_objectives,\n",
        "              show_plot=False, \n",
        "              show_info=False, \n",
        "              show_debug=False, \n",
        "              **kwargs):\n",
        "    \n",
        "    self.kwargs_str = '__'.join(['{}={}'.format(x[0], x[1]) for x in kwargs.items()])\n",
        "    self.individual = individual\n",
        "    self.n_individuals = n_individuals\n",
        "    self.objectives = objectives\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "    self.random = kwargs.get('random', True)\n",
        "    \n",
        "    self.fitness_values = np.zeros((self.n_individuals, len(self.objectives))) # Because of 2 objective functions\n",
        "    \n",
        "    if self.random:\n",
        "      self.list_individuals = [[self.createNewIndivid(**kwargs),0] for i in range(self.n_individuals)]\n",
        "    else:\n",
        "      self.list_individuals = [[self.setNewIndivid(i, **kwargs),0] for i in range(self.n_individuals)]\n",
        "\n",
        "    if self.show_info:\n",
        "      self.printPopulation()\n",
        "\n",
        "    if self.show_plot:\n",
        "      figure, ax = plt.subplots(1,1,  figsize=(6,5))\n",
        "      self.plotPopulation(ax)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  # Create New Individual. Randomly Generation \n",
        "  def createNewIndivid(self, **kwargs):\n",
        "    return(self.individual(**kwargs))\n",
        "\n",
        "\n",
        "  # Create New Individual  \n",
        "  def setNewIndivid(self, index, **kwargs):\n",
        "    list_points = kwargs.get('list_points', [])\n",
        "    n_points = kwargs.get('n_points', 0)\n",
        "    height = kwargs.get('height', ga_height)\n",
        "    width = kwargs.get('width', ga_width)\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    if (len(list_points) > 0) and (len(list_points) > index):\n",
        "      for i, individual in enumerate(list_points):\n",
        "        if (index == i):\n",
        "          for value in individual:\n",
        "            x.append(value[0])\n",
        "            y.append(value[1])\n",
        "\n",
        "      if (n_points == 0):\n",
        "        n_points = len(x)\n",
        "        \n",
        "      return(self.individual(n_points=n_points,\n",
        "                             height=height, \n",
        "                             width=width,\n",
        "                             x=x, \n",
        "                             y=y,\n",
        "                             random=self.random))\n",
        "    else:\n",
        "      return(self.individual())\n",
        "\n",
        "\n",
        "  # General Information of the Population\n",
        "  def printPopulation(self):\n",
        "    print(\"\\n--------------------------------\")\n",
        "    print(\"Population Created\")\n",
        "    print(\"--------------------------------\")\n",
        "    print(\"Number of individuals: \", str(self.n_individuals))\n",
        "    print(\"Randomly Population Generation: \", str(self.random))\n",
        "    print(\"Population Edited Parameters: \", str(self.kwargs_str))\n",
        "    print(\"-------------------------------- \\n\")\n",
        "\n",
        "\n",
        "  # Plot of the Population\n",
        "  def plotPopulation(self, ax, **kwargs):\n",
        "    ax.clear()\n",
        "    ax.set_xlabel('X axis')\n",
        "    ax.set_ylabel('Y axis')\n",
        "    ax.set_title('Population Representation')\n",
        "\n",
        "    for individual in self.list_individuals:\n",
        "      ax.plot(individual[0].x, individual[0].y)"
      ],
      "id": "tL1eHy7ANksX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "i3iEvpH2TX_f"
      },
      "id": "i3iEvpH2TX_f"
    },
    {
      "cell_type": "code",
      "source": [
        "class Fitness():\n",
        "  def __init__(self, \n",
        "              population=Population, \n",
        "              weights=ga_weights,\n",
        "              objectives=ga_objectives,\n",
        "              selection_method=ga_selection_method[0],\n",
        "              show_plot=False, \n",
        "              show_info=False, \n",
        "              show_debug=False):\n",
        "    \n",
        "    self.population = population\n",
        "    self.weights = weights\n",
        "    self.objectives = objectives,\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "\n",
        "    self.t_ideal = 0 # Ideal Time\n",
        "    self.d_ideal = 0 # Ideal Distance\n",
        "    self.sol = []\n",
        "\n",
        "    individual = self.population.list_individuals[0][0]\n",
        "    self.maxTime = self.getMaxTime(individual)\n",
        "    self.maxDistance = self.getMaxDistance(individual)\n",
        "    self.getBestCurve(individual)\n",
        "\n",
        "\n",
        "  # Update Population\n",
        "  def setPopulation(self, population):\n",
        "    self.population = population\n",
        "\n",
        "\n",
        "  # Calculation of Objectives and return Fitness Objectives separated\n",
        "  def getObjectives(self, individual):\n",
        "    g = 9.8\n",
        "    v = [0]\n",
        "    t = []\n",
        "    l = []\n",
        "\n",
        "    for i in range(len(individual.y)-1):\n",
        "      v.append(sqrt(2*g*(individual.y[i] - individual.y[i+1])+v[i]**2))\n",
        "      l.append(sqrt((individual.x[i] - individual.x[i+1])**2 + (individual.y[i] - individual.y[i+1])**2))\n",
        "      t.append(l[i] / v[i+1])\n",
        "\n",
        "    F1 = self.weights[0]*sum(t) # Time\n",
        "    F2 = self.weights[1]*sum(l) # Distance\n",
        "\n",
        "    return F1, F2\n",
        "\n",
        "\n",
        "  # Calculation of unique Fitness Objective\n",
        "  def getFitness(self, individual):\n",
        "    F1, F2 = self.getObjectives(individual)\n",
        "    return F1 + F2\n",
        "\n",
        "\n",
        "  # Calculation of Fitness Objectives. Return fitness of the entire population\n",
        "  def getFitnessPopulation(self, sort=False):\n",
        "    for individual in self.population.list_individuals:\n",
        "      individual[1] = self.getFitness(individual[0])\n",
        "      self.population.fitness_values[0], self.population.fitness_values[1] = self.getObjectives(individual[0])\n",
        "\n",
        "    if sort:\n",
        "      self.sortIndividuals()\n",
        "\n",
        "    if self.show_info:\n",
        "      self.printFitnessFunctions()\n",
        "\n",
        "    return self.population\n",
        "\n",
        "\n",
        "  # Sort Individuals by unique Fitness\n",
        "  def sortIndividuals(self):\n",
        "    list.sort(self.population.list_individuals, key=lambda fitness: fitness[1])\n",
        "\n",
        "\n",
        "  # Calculation of the Max Time taken. Calculation of normalization data\n",
        "  def getMaxTime(self, individual):\n",
        "    maxTime = sqrt((individual.x[0] - individual.x[-1])**2 + (individual.y[0] - individual.y[-1])**2)\n",
        "    return maxTime\n",
        "\n",
        "\n",
        "  # Calculation of the Max Distance taken. Calculation of normalization data\n",
        "  def getMaxDistance(self, individual):\n",
        "    maxDistance = (individual.x[-1] - individual.x[0]) + (individual.y[0] - individual.y[-1])\n",
        "    maxDistance *= individual.n_points\n",
        "    return maxDistance\n",
        "\n",
        "\n",
        "  # Calculation of the Ideal Time \n",
        "  def getBestCurve(self, individual):\n",
        "    w = individual.width\n",
        "    h = individual.height\n",
        "    sol_numeric_y = []\n",
        "\n",
        "    f_t = lambda t: np.cos(t)-1+ (-h/w)*(np.sin(t)-t)\n",
        "    t = fsolve(f_t,3.14)[0]\n",
        "\n",
        "    a = w/(t-sin(t))\n",
        "\n",
        "    t_range = np.linspace(0,t,individual.n_points)\n",
        "\n",
        "    x = lambda t: a*(t-np.sin(t))\n",
        "    y = lambda t: h + a*(np.cos(t)-1)\n",
        "\n",
        "    self.sol = (t_range, x, y)\n",
        "\n",
        "    for x_pt in individual.x:\n",
        "        f = lambda t: x(t)-x_pt\n",
        "        tval = fsolve(f,3.14)[0]\n",
        "        sol_numeric_y.append(y(tval))\n",
        "\n",
        "    temp_state = individual.y\n",
        "    individual.y = sol_numeric_y\n",
        "    individual.sol_numeric_y = sol_numeric_y\n",
        "    \n",
        "    self.t_ideal, self.d_ideal = self.getObjectives(individual)\n",
        "    individual.y = temp_state\n",
        "\n",
        "    if self.show_info:\n",
        "      print('\\n-------------------------------------')\n",
        "      print('Theoretical best time:', self.t_ideal, \"\\n\")\n",
        "      print('Theoretical best distance:', self.d_ideal, \"\\n\")\n",
        "      print('\\n-------------------------------------')\n",
        "\n",
        "\n",
        "  # General Information of the Fitness\n",
        "  def printFitnessFunctions(self):\n",
        "    print('\\n-------------------------------------')\n",
        "    print('Objective Fitness 1: ', self.objectives[0])\n",
        "    print('\\n')\n",
        "    for index, individual in enumerate(self.population.list_individuals):\n",
        "      print('Individual {:10}     |    W. Fitness: {:.4f}'.format(index, individual[1]))\n",
        "\n",
        "\n",
        "  # Plot of an Individual comparison with the Brachistochrone\n",
        "  def plotState(self, individual, ax, width, height, color='black', plot_sol=False, plot_label=False):\n",
        "    ax.clear()\n",
        "    ax.set_xlabel('X axis')\n",
        "    ax.set_ylabel('Y axis')\n",
        "    ax.set_title('Comparison Actual Result with Brachistochrone')\n",
        "\n",
        "    if plot_sol:\n",
        "      t = self.sol[0]\n",
        "      x = self.sol[1]\n",
        "      y = self.sol[2]\n",
        "      ax.plot(x(t), y(t), '-', color='gray')\n",
        "\n",
        "      if plot_label:\n",
        "        ax.text(0.7*width, 0.8*height, 'Ideal Time: {:.3f}'.format(self.t_ideal))\n",
        "\n",
        "    if plot_label:\n",
        "      time, distance = self.getObjectives(individual)\n",
        "      ax.text(0.7*width, 0.7*height, 'Current Time: {:.3f}'.format(time))\n",
        "\n",
        "    ax.plot(individual.x, individual.y, 'o-', color=color)\n",
        "\n",
        "\n",
        "  # Plot of the Best and Mean Fitness Function\n",
        "  def plotFitnessFunction(self, ax, best, mean):\n",
        "    ax.set_xlabel('Generations')\n",
        "    ax.set_ylabel('Fitness Function')\n",
        "    ax.set_title('Best and Mean Results')\n",
        "    ax.plot(best, label='best', color='dodgerblue')\n",
        "    ax.plot(mean, label='mean', color='tomato')\n",
        "    ax.legend()\n",
        "    ax.text(0.6*len(best), 0.8*max(best), 'best: {:.3f}\\nmean: {:.3f}'.format(best[-1], mean[-1]))\n"
      ],
      "metadata": {
        "id": "cDgCbW6CV950"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cDgCbW6CV950"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection"
      ],
      "metadata": {
        "id": "I6AL8YPHTdNK"
      },
      "id": "I6AL8YPHTdNK"
    },
    {
      "cell_type": "code",
      "source": [
        "class Selection():\n",
        "  def __init__(self,\n",
        "               population=Population, \n",
        "               ps=ga_ps,\n",
        "               show_plot=False,\n",
        "               show_info=False, \n",
        "               show_debug=False):\n",
        "    \n",
        "    self.population = population\n",
        "    self.parents = []\n",
        "    self.ps = ps\n",
        "    self.quantity_parents = 3\n",
        "\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "\n",
        "\n",
        "  # Probabilistic Selection\n",
        "  def getProbabilisticSelection(self):\n",
        "    probability = np.random.uniform(\n",
        "        low=0, high=1, size=self.population.n_individuals)\n",
        "    \n",
        "    probability = probability <= self.ps\n",
        "    if sum(probability == True) > 0:\n",
        "      self.quantity_parents = sum(probability == True)\n",
        "\n",
        "\n",
        "  # Get All new Parents using Tournament Selection\n",
        "  def getParentsSelection(self):\n",
        "    self.getProbabilisticSelection()\n",
        "    \n",
        "    for i in range(self.quantity_parents):\n",
        "      self.parents.append(self.tournamentSelection())\n",
        "\n",
        "    if self.show_info:\n",
        "      self.printParents()\n",
        "\n",
        "    return self.parents\n",
        "\n",
        "\n",
        "  # We select K individuals from the population at random and select the best \n",
        "  # out of these to become a parent\n",
        "  def tournamentSelection(self):\n",
        "    parents = random.choices(self.population.list_individuals, k=5)\n",
        "    list.sort(parents, key=lambda fitness: fitness[1])\n",
        "\n",
        "    return (parents[0])\n",
        "\n",
        "\n",
        "  # General Information of the Parents\n",
        "  def printParents(self):\n",
        "    print('\\n-------------------------------------')\n",
        "    print('Selection Parents')\n",
        "    print('\\n')\n",
        "    for index, individual in enumerate(self.parents):\n",
        "      print('Individual {:10}     |    Fitness: {:.4f}'.format(index, individual[1]))\n"
      ],
      "metadata": {
        "id": "n9-8KuygrGn6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "n9-8KuygrGn6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crossover"
      ],
      "metadata": {
        "id": "1Oss4a-wTgbW"
      },
      "id": "1Oss4a-wTgbW"
    },
    {
      "cell_type": "code",
      "source": [
        "class Crossover():\n",
        "  def __init__(self, \n",
        "               population=Population, \n",
        "               parents=ga_parents, \n",
        "               pc=ga_pc,\n",
        "               show_plot=False, \n",
        "               show_info=False, \n",
        "               show_debug=False):\n",
        " \n",
        "    self.population = population\n",
        "    self.parents = parents\n",
        "    self.new_individuals = []\n",
        "    self.pc = pc\n",
        "\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "\n",
        "\n",
        "  # Get New Individuals result of the Crossover using One Point Crossover operator\n",
        "  def getNewIndividuals(self):\n",
        "    random.shuffle(self.parents)\n",
        "    n_couple = int((len(self.parents)-1) / 2)\n",
        "    for i in range(n_couple+1):\n",
        "      new_child1, new_child2 = self.onePointCrossover(self.parents[i], self.parents[-(i-1)])\n",
        "      self.new_individuals.append(new_child1)\n",
        "      self.new_individuals.append(new_child2)\n",
        "\n",
        "    if self.show_info:\n",
        "      self.printNewPopulation()\n",
        "\n",
        "    return self.new_individuals\n",
        "\n",
        "\n",
        "  # A random crossover point is selected and the tails of its two parents are \n",
        "  # swapped to get new off-springs\n",
        "  def onePointCrossover(self, parent1, parent2):\n",
        "    new_child1 = deepcopy(parent1)\n",
        "    new_child2 = deepcopy(parent2)\n",
        "\n",
        "    r1 = randint(1,parent1[0].n_points-3)\n",
        "    r2 = randint(r1+1,parent2[0].n_points-2)\n",
        "\n",
        "    temp = new_child1[0].y[r1:r2]\n",
        "    new_child1[0].y[r1:r2] = new_child2[0].y[r1:r2]\n",
        "    new_child2[0].y[r1:r2] = temp\n",
        "\n",
        "    return(new_child1, new_child2)\n",
        "\n",
        "\n",
        "  # Result of the Crossover New Individuals\n",
        "  def printNewPopulation(self):\n",
        "    print('\\n-------------------------------------')\n",
        "    print('Crossover New Individuals')\n",
        "    print('\\n')\n",
        "    for index, individual in enumerate(self.new_individuals):\n",
        "      print('Individual {:10}     |    Individual Y:'.format(index), *individual[0].y, sep=', ')\n"
      ],
      "metadata": {
        "id": "79m3ovo2ryYp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "79m3ovo2ryYp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutation"
      ],
      "metadata": {
        "id": "3k1BhsXeTjpk"
      },
      "id": "3k1BhsXeTjpk"
    },
    {
      "cell_type": "code",
      "source": [
        "class Mutation():\n",
        "  def __init__(self, \n",
        "               new_individuals=ga_new_individuals, \n",
        "               pm=ga_pm,\n",
        "               show_plot=False, \n",
        "               show_info=False, \n",
        "               show_debug=False):\n",
        "    \n",
        "    self.new_individuals = new_individuals\n",
        "    self.pm = pm\n",
        "\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "\n",
        "\n",
        "  # Small random tweak in the chromosome to get a new solution\n",
        "  def randomSetMutation(self):\n",
        "    mutate_individual = []\n",
        "    mutate_individual.clear()\n",
        "\n",
        "    for individual in self.new_individuals:\n",
        "      mutate_individual.append(self.mutate(individual))\n",
        "\n",
        "    self.new_individuals = mutate_individual\n",
        "      \n",
        "    if self.show_info:\n",
        "      self.printMutation()\n",
        "\n",
        "    return self.new_individuals\n",
        "\n",
        "\n",
        "  # Random Resetting operator\n",
        "  def mutate(self, individual):\n",
        "    probability = np.random.uniform(\n",
        "    low=0, high=1, size=individual[0].n_points-2)\n",
        "\n",
        "    probability = probability <= self.pm\n",
        "\n",
        "    mutate_individual = deepcopy(individual)\n",
        "    height = individual[0].height\n",
        "  \n",
        "    if sum(probability == True) > 0:\n",
        "      mutate_individual[0].y = mutate_individual[0].y[1: mutate_individual[0].n_points-1]\n",
        "\n",
        "      # Mutate Random Process\n",
        "      for i in np.where(probability)[0]:\n",
        "        frac = 1\n",
        "        mutate_individual[0].y[i] = (-height/frac + random.random()*(height - (-height/frac)))\n",
        "      \n",
        "      mutate_individual[0].y = [height] + mutate_individual[0].y + [0]\n",
        "\n",
        "    return mutate_individual \n",
        "\n",
        "\n",
        "  # A random value from the set of permissible values is assigned to a randomly chosen gene\n",
        "  def mutateSingle(self):\n",
        "    index = randint(1, self.n_segments-1)\n",
        "    new_height = self.y[index] + np.random.normal(scale=self.mutate_strength)\n",
        "    \n",
        "    if new_height < self.height:\n",
        "      self.y[index] = new_height\n",
        "\n",
        "\n",
        "  # Result of the Mutation of the New Individuals\n",
        "  def printMutation(self):\n",
        "    print('\\n-------------------------------------')\n",
        "    print('Mutation New Individuals')\n",
        "    print('\\n')\n",
        "    for index, individual in enumerate(self.new_individuals):\n",
        "      print('Individual {:10}     |    Individual Y:'.format(index), *individual[0].y, sep=', ')\n"
      ],
      "metadata": {
        "id": "BKhA67J2qzUD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BKhA67J2qzUD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Survivor Selection"
      ],
      "metadata": {
        "id": "Cfmiw9L2rXII"
      },
      "id": "Cfmiw9L2rXII"
    },
    {
      "cell_type": "code",
      "source": [
        "class Survivor_Selection():\n",
        "  def __init__(self, \n",
        "               population=Population, \n",
        "               new_individuals=ga_new_individuals,\n",
        "               objectives=ga_objectives,\n",
        "               show_plot=False, \n",
        "               show_info=False, \n",
        "               show_debug=False):\n",
        "    \n",
        "    self.population = population\n",
        "    self.new_individuals = new_individuals\n",
        "    self.objectives = objectives\n",
        "    self.show_plot = show_plot\n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "\n",
        "    self.new_population = []\n",
        "\n",
        "\n",
        "  # \n",
        "  def getNewPopulation(self):\n",
        "    self.new_population =  self.population.list_individuals + self.new_individuals\n",
        "\n",
        "    fitness = Fitness(self.population)\n",
        "    fitness_values = np.zeros((len(self.new_population), len(self.objectives)))\n",
        "\n",
        "    for i, individual in enumerate(self.new_population):\n",
        "      fitness_values[i][0], fitness_values[i][1] = fitness.getObjectives(individual[0])\n",
        "    \n",
        "    pareto_front_index = []\n",
        "    pop_index_0 = np.arange((len(self.new_population)))\n",
        "    pop_index = np.arange((len(self.new_population)))\n",
        "\n",
        "    while len(pareto_front_index) < self.population.n_individuals:\n",
        "      new_pareto_front = self.paretoFront(fitness_values[pop_index_0, :], pop_index_0)\n",
        "      total_pareto_size = len(pareto_front_index) + len(new_pareto_front)\n",
        "\n",
        "      if total_pareto_size > self.population.n_individuals:\n",
        "        number_solutions_needed = self.population.n_individuals - len(pareto_front_index)\n",
        "        selected_population_index = self.removeWithCrowding(fitness_values[new_pareto_front], number_solutions_needed)\n",
        "        new_pareto_front = new_pareto_front[selected_population_index]\n",
        "    \n",
        "      pareto_front_index = np.hstack((pareto_front_index, new_pareto_front))\n",
        "      remaining_index = set(pop_index) - set(pareto_front_index)\n",
        "      pop_index_0 = np.array(list(remaining_index))\n",
        "\n",
        "    selected_population_index = [pareto_front_index.astype(int)][0]\n",
        "    \n",
        "    self.new_population = [self.new_population[i] for i in selected_population_index]\n",
        "    self.population.list_individuals = self.new_population\n",
        "    \n",
        "    fitness.setPopulation(self.population)\n",
        "    fitness.getFitnessPopulation()\n",
        "\n",
        "    self.population = fitness.population\n",
        "\n",
        "    # Update Fitness on the population\n",
        "    for i, individual in enumerate(self.population.list_individuals):\n",
        "      self.population.fitness_values[i][0], self.population.fitness_values[i][1] = fitness.getObjectives(individual[0])\n",
        "\n",
        "    self.t_best, self.d_best, self.mean = self.getBestandMean()\n",
        "\n",
        "    if self.show_info:\n",
        "      self.printSurvivor()\n",
        "\n",
        "    if self.show_plot:\n",
        "      figure, ax = plt.subplots(1,1,  figsize=(6,5))\n",
        "      self.plotParetoFront(ax, fitness_values)\n",
        "      plt.show()\n",
        "\n",
        "    return self.population\n",
        "\n",
        "\n",
        "  # Crowding Distance Calculation\n",
        "  def crowdingCalculation(self, fitness_values):\n",
        "    population_size = len(fitness_values[:, 0])\n",
        "    dimension = len(fitness_values[0, :])\n",
        "    crowding = np.zeros((population_size, dimension))\n",
        "\n",
        "    normalize_fitness_values = (fitness_values - fitness_values.min(0))/fitness_values.ptp(0)\n",
        "\n",
        "    for i in range(dimension):\n",
        "      crowding_results = np.zeros(population_size)\n",
        "      crowding_results[0] = 1\n",
        "      crowding_results[population_size - 1] = 1\n",
        "      sorting_normalize_fitness_values = np.sort(normalize_fitness_values[:, i])\n",
        "      sorting_normalized_values_index = np.argsort(normalize_fitness_values[:, i])\n",
        "\n",
        "      # Crowding Distance Calculation\n",
        "      crowding_results[1:population_size-1] = (sorting_normalize_fitness_values[2:population_size] - sorting_normalized_values_index[2:population_size])\n",
        "      re_sorting = np.argsort(sorting_normalized_values_index)\n",
        "      crowding[:,i] = crowding_results[re_sorting]\n",
        "\n",
        "    crowding_distance = np.sum(crowding, axis=1) # crowding distance of each solution\n",
        "    \n",
        "    return crowding_distance\n",
        "\n",
        "\n",
        "  # Remove not good values depending on the crowding Distance Calculation\n",
        "  def removeWithCrowding(self, fitness_values, number_solutions_needed):\n",
        "    population_index = np.arange(fitness_values.shape[0])\n",
        "    crowding_distance = self.crowdingCalculation(fitness_values)\n",
        "    selected_population_index = np.zeros((number_solutions_needed))\n",
        "    selected_fitness_values = np.zeros((number_solutions_needed, len(fitness_values[0, :])))\n",
        "\n",
        "    for i in range(number_solutions_needed):\n",
        "      population_size = population_index.shape[0]\n",
        "      a = random.randint(0, population_size - 1) # Solution Random 1\n",
        "      b = random.randint(0, population_size - 1) # Solution Random 2\n",
        "      if crowding_distance[a] >= crowding_distance[b]:\n",
        "        # Solution 1 is better than solution 2\n",
        "        selected_population_index[i] = population_index[a]\n",
        "        selected_fitness_values[i, :] = fitness_values[a, :]\n",
        "        population_index = np.delete(population_index, (a), axis=0)\n",
        "        fitness_values = np.delete(fitness_values, (a), axis=0)\n",
        "        crowding_distance = np.delete(crowding_distance, (a), axis=0)\n",
        "\n",
        "      else:\n",
        "        # Solution 2 is better than solution 1\n",
        "        selected_population_index[i] = population_index[b]\n",
        "        selected_fitness_values[i, :] = fitness_values[b, :]\n",
        "        population_index = np.delete(population_index, (b), axis=0)\n",
        "        fitness_values = np.delete(fitness_values, (b), axis=0)\n",
        "        crowding_distance = np.delete(crowding_distance, (b), axis=0)\n",
        "    \n",
        "    selected_population_index = np.asarray(selected_population_index, dtype=int) # Convert the data to integer \n",
        "     \n",
        "    return selected_population_index\n",
        "\n",
        "\n",
        "  # Creating Pareto Front\n",
        "  def paretoFront(self, fitness_values, population_index):\n",
        "    population_size = fitness_values.shape[0]\n",
        "    # Initially assume all solutions are in pareto front by using \"1\"\n",
        "    pareto_front = np.ones(population_size, dtype=bool) \n",
        "    for i in range(population_size):\n",
        "        for j in range(population_size):\n",
        "                if all(fitness_values[j] <= fitness_values[i]) and any(fitness_values[j] < fitness_values[i]):\n",
        "                  pareto_front[i] = 0\n",
        "                  break\n",
        "    return population_index[pareto_front]\n",
        "\n",
        "\n",
        "  # Return one of the set of best solutions \n",
        "  def getBestandMean(self):\n",
        "    t_best = self.population.fitness_values[0][0]\n",
        "    d_best = self.population.fitness_values[0][1]\n",
        "\n",
        "    mean = sum([individual[1] for individual in self.population.list_individuals])/(1.0*len(self.population.list_individuals))\n",
        "    return((t_best, d_best, mean))\n",
        "\n",
        "\n",
        "  # Result of New Population\n",
        "  def printSurvivor(self):\n",
        "    print('\\n-------------------------------------')\n",
        "    print('Objective Fitness 1: ', self.objectives[0])\n",
        "    print('\\n')\n",
        "    for index, individual in enumerate(self.population.list_individuals):\n",
        "      print('Individual {:10}     |    Fitness: {:.4f}'.format(index, individual[1]))\n",
        "\n",
        "\n",
        "  # Ploting Pareto Front\n",
        "  def plotParetoFront(self, ax, fitness_values, maxX=False, maxY=False):\n",
        "    ax.clear()\n",
        "    ax.set_xlabel(self.objectives[0])\n",
        "    ax.set_ylabel(self.objectives[1])\n",
        "    ax.set_title('Pareto Frontier')\n",
        "\n",
        "    # Pareto frontier selection process\n",
        "    time = [fitness[0] for fitness in fitness_values]\n",
        "    distance = [fitness[1] for fitness in fitness_values]\n",
        "\n",
        "    sorted_list = sorted([[time[i], distance[i]] for i in range(len(time))], reverse=maxY)\n",
        "    pareto_front = [sorted_list[0]]\n",
        "    \n",
        "    for pair in sorted_list[1:]:\n",
        "        if maxY:\n",
        "            if pair[1] >= pareto_front[-1][1]:\n",
        "                pareto_front.append(pair)\n",
        "        else:\n",
        "            if pair[1] <= pareto_front[-1][1]:\n",
        "                pareto_front.append(pair)\n",
        "\n",
        "    ax.scatter(time, distance)\n",
        "    x = [pair[0] for pair in pareto_front]\n",
        "    y = [pair[1] for pair in pareto_front]\n",
        "    ax.plot(x, y)"
      ],
      "metadata": {
        "id": "OB2UwSZprZ6G"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OB2UwSZprZ6G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtTbqD-tY4NC"
      },
      "source": [
        "## Genetic Algorithm execution"
      ],
      "id": "XtTbqD-tY4NC"
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneticAlgorithm():\n",
        "\n",
        "  # Variable = Variation of the Probability between epochs\n",
        "  def __init__(self, \n",
        "               population=Population, \n",
        "               n_generations=ga_n_generations,\n",
        "               objectives=ga_objectives,\n",
        "               selection_method=ga_selection_method[0],\n",
        "               misc_runs_dir=ga_misc_runs_dir,\n",
        "               evolution_dir=ga_evolution_dir,\n",
        "               objectives_dir=ga_objectives_dir,\n",
        "               max_frames=ga_max_frames,\n",
        "               ps=ga_ps, \n",
        "               pc=ga_pc, \n",
        "               pm=ga_pm,\n",
        "               p_variable=ga_p_variable,\n",
        "               show_plot=False, \n",
        "               show_info=False, \n",
        "               show_debug=False):   \n",
        "\n",
        "    self.population = population\n",
        "    self.n_generations = n_generations\n",
        "    self.objectives = objectives\n",
        "    self.selection_method = selection_method\n",
        "    self.misc_runs_dir = misc_runs_dir\n",
        "    self.evolution_dir = evolution_dir\n",
        "    self.objectives_dir = objectives_dir\n",
        "    self.ps = ps \n",
        "    self.pc = pc \n",
        "    self.pm = pm\n",
        "    self.p_variable = p_variable\n",
        "    self.show_plot = show_plot \n",
        "    self.show_info = show_info\n",
        "    self.show_debug = show_debug\n",
        "    self.max_frames = max_frames\n",
        "    \n",
        "    self.parents = []\n",
        "    self.new_individuals = []\n",
        "\n",
        "    # Calculation of the interval of variation\n",
        "    if p_variable:\n",
        "      self.interval_ps = int((1-self.ps)/self.n_generations)\n",
        "      self.interval_pc = int((1-self.pc)/self.n_generations)\n",
        "      self.interval_pm = int((1-self.pm)/self.n_generations)\n",
        "    \n",
        "    self.optimization()\n",
        "\n",
        "\n",
        "  # For change the probability, we define: (Max probability - Min Probability)/ Generations\n",
        "  # In all the Generations the algorithm is going to be more accurate until arrive to the minimum desired\n",
        "  def changeProbability(self):\n",
        "    self.ps -= self.interval_ps\n",
        "    self.pc -= self.interval_pc\n",
        "    self.pm -= self.interval_pm\n",
        "\n",
        "\n",
        "  # Genetic Algorithm. Optimization of the Population\n",
        "  def optimization(self):\n",
        "    start = datetime.now()\n",
        "\n",
        "    # Show Plot Best Results\n",
        "    t_best = []\n",
        "    d_best = []\n",
        "    mean = []\n",
        "\n",
        "    # Save on Logs\n",
        "    logs = []\n",
        "\n",
        "    # Divide Images on frames\n",
        "    if self.n_generations <= self.max_frames:\n",
        "      interval = [i for i in range(self.n_generations)]\n",
        "      interval_frames = interval\n",
        "    else:\n",
        "      interval = int(self.n_generations/self.max_frames)\n",
        "      interval_frames = [i*interval for i in range(self.max_frames)]\n",
        "\n",
        "    for i in range(self.n_generations):\n",
        "      fitness = Fitness(self.population)\n",
        "      self.population = fitness.getFitnessPopulation()\n",
        "      selection = Selection(self.population, self.ps)\n",
        "      self.parents = selection.getParentsSelection()\n",
        "      crossover = Crossover(self.population, self.parents, self.pc)\n",
        "      self.new_individuals = crossover.getNewIndividuals()\n",
        "      mutation = Mutation(self.new_individuals, self.pm)\n",
        "      self.new_individuals = mutation.randomSetMutation()\n",
        "      survivor_selection = Survivor_Selection(self.population, self.new_individuals)\n",
        "      self.population = survivor_selection.getNewPopulation()\n",
        "            \n",
        "      if self.p_variable:\n",
        "        self.changeProbability()\n",
        "\n",
        "      t_best.append(survivor_selection.t_best)\n",
        "      d_best.append(survivor_selection.d_best)\n",
        "      mean.append(survivor_selection.mean)\n",
        "\n",
        "      if self.show_info:\n",
        "        if i in interval_frames:\n",
        "          logs.append('Generation {}, Best Time = {:.3f}, Best Distance = {:.3f}, Population size = {}'.format(i, survivor_selection.t_best, survivor_selection.d_best, len(self.population.list_individuals)))\n",
        "          print(logs[-1])\n",
        "\n",
        "          if self.show_plot:\n",
        "            figure, ax = plt.subplots(2, 1, figsize=(6,8))\n",
        "            plt.subplots_adjust(left=0.1,\n",
        "                        bottom=0.1, \n",
        "                        right=0.9, \n",
        "                        top=0.9, \n",
        "                        wspace=0.4, \n",
        "                        hspace=0.4)\n",
        "              \n",
        "            # Population Representation\n",
        "            self.population.plotPopulation(ax[0])\n",
        "              \n",
        "            # Pareto Function\n",
        "            survivor_selection.plotParetoFront(ax[1], self.population.fitness_values)\n",
        "\n",
        "            # Combine all the operations and display\n",
        "            print(f'{self.evolution_dir}/{i}.png')\n",
        "            plt.savefig(f'{self.evolution_dir}/{i}.png')\n",
        "            plt.show()\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "    # Generations Finish\n",
        "    if self.show_info:\n",
        "      individual = self.population.list_individuals[0][0]\n",
        "\n",
        "      # Initialise the subplot function using number of rows=2 and columns=2\n",
        "      figure, ax = plt.subplots(2, 2, figsize=(15,13))\n",
        "      plt.subplots_adjust(left=0.1,\n",
        "                  bottom=0.1, \n",
        "                  right=0.9, \n",
        "                  top=0.9, \n",
        "                  wspace=0.4, \n",
        "                  hspace=0.4)\n",
        "        \n",
        "      # Population Representation\n",
        "      self.population.plotPopulation(ax[0, 0])\n",
        "        \n",
        "      # Pareto Function\n",
        "      survivor_selection.plotParetoFront(ax[0, 1], self.population.fitness_values)\n",
        "\n",
        "      # Fitness Function\n",
        "      fitness.plotFitnessFunction(ax[1, 0], t_best, mean)\n",
        "\n",
        "      # Best Function\n",
        "      fitness.plotState(individual, ax[1, 1], individual.width, individual.height, color='tomato', plot_sol=True, plot_label=True)\n",
        "\n",
        "      plt.savefig(f'{self.misc_runs_dir}/best.png')\n",
        "      plt.show()\n",
        "\n",
        "      end = datetime.now()\n",
        "\n",
        "    exportTXT(logs, self.misc_runs_dir)\n",
        "\n",
        "    print('\\n-------------------------------------')\n",
        "    print(\"Process Complete\")\n",
        "    print('-------------------------------------\\n')\n",
        "    print(\"Object Fitness:\", *self.objectives, sep=', ')\n",
        "    print(\"Best Time\", survivor_selection.t_best)\n",
        "    print(\"Best Distance\", survivor_selection.d_best)\n",
        "    print(\"Ideal Time\", fitness.t_ideal)\n",
        "    print(\"Ideal Distance\", fitness.d_ideal)\n",
        "    print(\"Number of Generations\", self.n_generations)\n",
        "    print(\"Time Process: {}\".format(end - start))\n",
        "    print(\"\\n-------------------------------------------\\n\")\n",
        "\n",
        "    if self.show_plot:\n",
        "      print('\\n-------------------------------------')\n",
        "      print(\"Evolution Representation\")\n",
        "      print('-------------------------------------\\n')\n",
        "      fp_out = self.evolution_dir + f'/gif.gif'\n",
        "      exportGIF(self.evolution_dir, fp_out)\n",
        "      importGIF(self.evolution_dir)"
      ],
      "metadata": {
        "id": "8Y0nIaF0XClQ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8Y0nIaF0XClQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Section MOEA"
      ],
      "metadata": {
        "id": "i5fY9l21CuPl"
      },
      "id": "i5fY9l21CuPl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjhuHH38cb2g"
      },
      "source": [
        "### Population Random Generation"
      ],
      "id": "LjhuHH38cb2g"
    },
    {
      "cell_type": "code",
      "source": [
        "population = Population(Individual, \n",
        "                        n_individuals=ga_n_individuals, \n",
        "                        n_points=ga_n_points, \n",
        "                        height=ga_height, \n",
        "                        width=ga_width, \n",
        "                        show_plot=ga_show_plot, \n",
        "                        show_info=ga_show_info, \n",
        "                        show_debug=ga_show_debug)\n",
        "\n",
        "# Preparation of environment folders \n",
        "makeFolders()\n",
        "initConfig(folder=ga_misc_runs_dir, set_global=False)\n",
        "\n",
        "GeneticAlgorithm(population=population,\n",
        "                 n_generations=ga_n_generations,\n",
        "                 objectives=ga_objectives,\n",
        "                 misc_runs_dir=ga_misc_runs_dir,\n",
        "                 evolution_dir=ga_evolution_dir,\n",
        "                 objectives_dir=ga_objectives_dir,\n",
        "                 ps=ga_ps,\n",
        "                 pc=ga_pc,\n",
        "                 pm=ga_pm,\n",
        "                 p_variable=ga_p_variable,\n",
        "                 show_plot=ga_show_plot,\n",
        "                 show_info=ga_show_info, \n",
        "                 show_debug=ga_show_debug)\n",
        "\n"
      ],
      "metadata": {
        "id": "1fcvhcuh4iA0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1fcvhcuh4iA0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Benchmark on Hybrid Optimizer"
      ],
      "metadata": {
        "id": "y6K4O4w8HxeP"
      },
      "id": "y6K4O4w8HxeP"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc-autonumbering": true,
    "toc-showcode": true,
    "colab": {
      "name": "MOEA_Brachistochrone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}